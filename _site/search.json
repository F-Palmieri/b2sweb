[
  {
    "objectID": "team/rafael-leon-carrasco/index.html",
    "href": "team/rafael-leon-carrasco/index.html",
    "title": "Rafael León Carrasco",
    "section": "",
    "text": "Hello! My name is Rafael León Carrasco. I have a Bachelor’s Degree in Chemical Engineering and a Master’s in Interdisciplinary & Innovative Engineering by the UPC (Polytechnic University of Catalonia). I am an engineer passionate about technology and data science. My work focuses on developing Machine Learning models for diagnosing rare diseases, and collaborating closely with medical institutions such as Hospital Sant Joan de Déu and Hospital Sant Pau for data analysis. I specialize in using graph models and neural networks to extract insights from clinical data. Moreover I have programming and server management experience.\nWith a strong background in engineering and research experience, I enjoy facing complex challenges and finding efficient solutions. Additionally, I quickly adapt to new technological landscapes required.\n\n\n\n\nMay 2024 – Present\n- Development of ML algorithms for diagnosing rare kidney diseases.\n- Performance analysis of diagnostic models.\n- Maintenance of the HDSI Share4Rare server (Django) and diagnostic platform (Springboot).\n\n\n\nNovember 2022 – May 2024\n- Development of diagnostic platforms for rare kidney diseases in collaboration with Hospital Sant Pau.\n- Clinical data analysis and server maintenance.\n\n\n\nJuly 2023 – July 2024\n- Analysis of rare disease data to improve early diagnosis.\n- Application of advanced statistical techniques and ML models.\n\n\n\n\n\nProgramming in Java and Python.\n\nExperience with Machine Learning, graph models, and statistical analysis.\n\nFamiliarity with servers Nginx, Apache, Django, and Springboot.\n\nProblem-solving skills and teamwork experience.\n\nOrganization and adaptability to new technological challenges.\n\n\n\n\n\n\n1. # 2068 Factors affecting disease progression in individuals with heterozygous COL4A3/COL4A4 pathogenic variantsMP Teran, M Furlano, M Pybus, VM Jiménez, E Gomá-Garcés, IG Carrillo, …Nephrology Dialysis Transplantation, Vol. 39 (Supplement_1), gfae069-0238-2068, Issue (2024)[DOI]\n\n\n\n2. # 4037 DEVELOPMENT OF AN EXPERT MODEL FOR THE DIAGNOSIS OF INHERITED KIDNEY DISEASESLF de Arizón, ERV Ramírez, R Leon, MP Teran, M Furlano, M Vallverdu, …Nephrology Dialysis Transplantation, Vol. 38 (Supplement_1), gfad063c_4037, Issue (2023)[DOI]\n\n\n\n3. Analysis of clinical diagnostics in human genetics with semantic similarity searches in ontologiesR León CarrascoUniversitat Politècnica de Catalunya, Vol. , Issue (2022)[DOI]\n\n\n\n4. Modelando el paisaje de energía libre de una moléculaR Leon CarrascoUniversitat Politècnica de Catalunya, Vol. , Issue (2019)[DOI]\n\n\n5. Modelando el paisaje de energía libre de una moléculaRL CarrascoUniversitat Politècnica de Catalunya. Escola d’Enginyeria de Barcelona Est, Vol. , Issue (2019)[DOI]"
  },
  {
    "objectID": "team/rafael-leon-carrasco/index.html#bio",
    "href": "team/rafael-leon-carrasco/index.html#bio",
    "title": "Rafael León Carrasco",
    "section": "",
    "text": "Hello! My name is Rafael León Carrasco. I have a Bachelor’s Degree in Chemical Engineering and a Master’s in Interdisciplinary & Innovative Engineering by the UPC (Polytechnic University of Catalonia). I am an engineer passionate about technology and data science. My work focuses on developing Machine Learning models for diagnosing rare diseases, and collaborating closely with medical institutions such as Hospital Sant Joan de Déu and Hospital Sant Pau for data analysis. I specialize in using graph models and neural networks to extract insights from clinical data. Moreover I have programming and server management experience.\nWith a strong background in engineering and research experience, I enjoy facing complex challenges and finding efficient solutions. Additionally, I quickly adapt to new technological landscapes required.\n\n\n\n\nMay 2024 – Present\n- Development of ML algorithms for diagnosing rare kidney diseases.\n- Performance analysis of diagnostic models.\n- Maintenance of the HDSI Share4Rare server (Django) and diagnostic platform (Springboot).\n\n\n\nNovember 2022 – May 2024\n- Development of diagnostic platforms for rare kidney diseases in collaboration with Hospital Sant Pau.\n- Clinical data analysis and server maintenance.\n\n\n\nJuly 2023 – July 2024\n- Analysis of rare disease data to improve early diagnosis.\n- Application of advanced statistical techniques and ML models.\n\n\n\n\n\nProgramming in Java and Python.\n\nExperience with Machine Learning, graph models, and statistical analysis.\n\nFamiliarity with servers Nginx, Apache, Django, and Springboot.\n\nProblem-solving skills and teamwork experience.\n\nOrganization and adaptability to new technological challenges.\n\n\n\n\n\n\n1. # 2068 Factors affecting disease progression in individuals with heterozygous COL4A3/COL4A4 pathogenic variantsMP Teran, M Furlano, M Pybus, VM Jiménez, E Gomá-Garcés, IG Carrillo, …Nephrology Dialysis Transplantation, Vol. 39 (Supplement_1), gfae069-0238-2068, Issue (2024)[DOI]\n\n\n\n2. # 4037 DEVELOPMENT OF AN EXPERT MODEL FOR THE DIAGNOSIS OF INHERITED KIDNEY DISEASESLF de Arizón, ERV Ramírez, R Leon, MP Teran, M Furlano, M Vallverdu, …Nephrology Dialysis Transplantation, Vol. 38 (Supplement_1), gfad063c_4037, Issue (2023)[DOI]\n\n\n\n3. Analysis of clinical diagnostics in human genetics with semantic similarity searches in ontologiesR León CarrascoUniversitat Politècnica de Catalunya, Vol. , Issue (2022)[DOI]\n\n\n\n4. Modelando el paisaje de energía libre de una moléculaR Leon CarrascoUniversitat Politècnica de Catalunya, Vol. , Issue (2019)[DOI]\n\n\n5. Modelando el paisaje de energía libre de una moléculaRL CarrascoUniversitat Politècnica de Catalunya. Escola d’Enginyeria de Barcelona Est, Vol. , Issue (2019)[DOI]"
  },
  {
    "objectID": "team/rafael-leon-carrasco/index.html#professional-experience",
    "href": "team/rafael-leon-carrasco/index.html#professional-experience",
    "title": "Rafael León Carrasco",
    "section": "",
    "text": "May 2024 – Present\n- Development of ML algorithms for diagnosing rare kidney diseases.\n- Performance analysis of diagnostic models.\n- Maintenance of the HDSI Share4Rare server (Django) and diagnostic platform (Springboot).\n\n\n\nNovember 2022 – May 2024\n- Development of diagnostic platforms for rare kidney diseases in collaboration with Hospital Sant Pau.\n- Clinical data analysis and server maintenance.\n\n\n\nJuly 2023 – July 2024\n- Analysis of rare disease data to improve early diagnosis.\n- Application of advanced statistical techniques and ML models."
  },
  {
    "objectID": "team/rafael-leon-carrasco/index.html#skills",
    "href": "team/rafael-leon-carrasco/index.html#skills",
    "title": "Rafael León Carrasco",
    "section": "",
    "text": "Programming in Java and Python.\n\nExperience with Machine Learning, graph models, and statistical analysis.\n\nFamiliarity with servers Nginx, Apache, Django, and Springboot.\n\nProblem-solving skills and teamwork experience.\n\nOrganization and adaptability to new technological challenges."
  },
  {
    "objectID": "team/rafael-leon-carrasco/index.html#publications",
    "href": "team/rafael-leon-carrasco/index.html#publications",
    "title": "Rafael León Carrasco",
    "section": "",
    "text": "1. # 2068 Factors affecting disease progression in individuals with heterozygous COL4A3/COL4A4 pathogenic variantsMP Teran, M Furlano, M Pybus, VM Jiménez, E Gomá-Garcés, IG Carrillo, …Nephrology Dialysis Transplantation, Vol. 39 (Supplement_1), gfae069-0238-2068, Issue (2024)[DOI]\n\n\n\n2. # 4037 DEVELOPMENT OF AN EXPERT MODEL FOR THE DIAGNOSIS OF INHERITED KIDNEY DISEASESLF de Arizón, ERV Ramírez, R Leon, MP Teran, M Furlano, M Vallverdu, …Nephrology Dialysis Transplantation, Vol. 38 (Supplement_1), gfad063c_4037, Issue (2023)[DOI]\n\n\n\n3. Analysis of clinical diagnostics in human genetics with semantic similarity searches in ontologiesR León CarrascoUniversitat Politècnica de Catalunya, Vol. , Issue (2022)[DOI]\n\n\n\n4. Modelando el paisaje de energía libre de una moléculaR Leon CarrascoUniversitat Politècnica de Catalunya, Vol. , Issue (2019)[DOI]\n\n\n5. Modelando el paisaje de energía libre de una moléculaRL CarrascoUniversitat Politècnica de Catalunya. Escola d’Enginyeria de Barcelona Est, Vol. , Issue (2019)[DOI]"
  },
  {
    "objectID": "team/visiting.html",
    "href": "team/visiting.html",
    "title": "Visiting Fellows",
    "section": "",
    "text": "Investigadora de la Facultad de Ingeniería, Universidad Panamericana\n\nhttps://www.up.edu.mx/investigacion/antonieta-martinez-velasco/",
    "crumbs": [
      "Our Team",
      "Visiting fellows"
    ]
  },
  {
    "objectID": "team/visiting.html#current",
    "href": "team/visiting.html#current",
    "title": "Visiting Fellows",
    "section": "",
    "text": "Investigadora de la Facultad de Ingeniería, Universidad Panamericana\n\nhttps://www.up.edu.mx/investigacion/antonieta-martinez-velasco/",
    "crumbs": [
      "Our Team",
      "Visiting fellows"
    ]
  },
  {
    "objectID": "team/visiting.html#former-visiting-fellows",
    "href": "team/visiting.html#former-visiting-fellows",
    "title": "Visiting Fellows",
    "section": "Former Visiting Fellows",
    "text": "Former Visiting Fellows",
    "crumbs": [
      "Our Team",
      "Visiting fellows"
    ]
  },
  {
    "objectID": "team/alexandre-perera-lluna/index.html",
    "href": "team/alexandre-perera-lluna/index.html",
    "title": "Alexandre Perera Lluna",
    "section": "",
    "text": "Welcome to my site. My name is Alexandre Perera Lluna, sometimes Alex Perera. I hold a degree in Physics, a second degree in Electrical Engineering, and a PhD in Physics from the University of Barcelona. I currently lead the B2SLab, which is part of the Institut de Recerca i Innovació en Salut (IRIS), formerly the Research Center for Biomedical Engineering (CREB) at the Universitat Politècnica de Catalunya (Polytechnic University of Catalonia, UPC), located in the beautiful city of Barcelona. It is a fantastic place for research, culture, and leisure—I truly love this city.\nAt B2SLab, we integrate Data Science, Bioinformatics, and Bioengineering. My main interests include predicting disease trajectories using Transformer and Linear models, as well as applying machine learning to Rare Diseases. I also have experience in data integration, data fusion, metabolomics, functional enrichment, and bioengineering. Since 2022, I have been a full professor at the Universitat Politècnica de Catalunya.\n\nIn 2019, I was appointed as the head of the Research Center for Biomedical Engineering at UPC (CREB-UPC, Centre de Recerca en Enginyeria Biomèdica).\nI also coordinate a fascinating project named Xartec Salut."
  },
  {
    "objectID": "team/alexandre-perera-lluna/index.html#bio",
    "href": "team/alexandre-perera-lluna/index.html#bio",
    "title": "Alexandre Perera Lluna",
    "section": "",
    "text": "Welcome to my site. My name is Alexandre Perera Lluna, sometimes Alex Perera. I hold a degree in Physics, a second degree in Electrical Engineering, and a PhD in Physics from the University of Barcelona. I currently lead the B2SLab, which is part of the Institut de Recerca i Innovació en Salut (IRIS), formerly the Research Center for Biomedical Engineering (CREB) at the Universitat Politècnica de Catalunya (Polytechnic University of Catalonia, UPC), located in the beautiful city of Barcelona. It is a fantastic place for research, culture, and leisure—I truly love this city.\nAt B2SLab, we integrate Data Science, Bioinformatics, and Bioengineering. My main interests include predicting disease trajectories using Transformer and Linear models, as well as applying machine learning to Rare Diseases. I also have experience in data integration, data fusion, metabolomics, functional enrichment, and bioengineering. Since 2022, I have been a full professor at the Universitat Politècnica de Catalunya.\n\nIn 2019, I was appointed as the head of the Research Center for Biomedical Engineering at UPC (CREB-UPC, Centre de Recerca en Enginyeria Biomèdica).\nI also coordinate a fascinating project named Xartec Salut."
  },
  {
    "objectID": "team/alexandre-perera-lluna/index.html#social-networks",
    "href": "team/alexandre-perera-lluna/index.html#social-networks",
    "title": "Alexandre Perera Lluna",
    "section": "Social Networks",
    "text": "Social Networks\n\nFind me on my profile on\n\nMastodon\nBlue Sky\n\nNo, we do not use X nor twitter, and we will not use it for the time being"
  },
  {
    "objectID": "team/alexandre-perera-lluna/index.html#teaching",
    "href": "team/alexandre-perera-lluna/index.html#teaching",
    "title": "Alexandre Perera Lluna",
    "section": "Teaching",
    "text": "Teaching\nI teach several subjects, including:\n\nIntroduction to Bioinformatics.\nData Mining for Biomedical Databases.\nScientific computing.\nMachine learning.\nEmbedded and real time computing."
  },
  {
    "objectID": "team/alexandre-perera-lluna/index.html#ongoing-phd-thesis",
    "href": "team/alexandre-perera-lluna/index.html#ongoing-phd-thesis",
    "title": "Alexandre Perera Lluna",
    "section": "Ongoing PhD Thesis",
    "text": "Ongoing PhD Thesis\n\nMaria Barranco1\nEnrico Manzini\nJoshua Llano\nJoana Gelabert\nBlanca Aleajos\nHelena Rodriguez Gonzalez\nPol Solà\nPol Canal\nPol Ezquerra\nAitor Moruno"
  },
  {
    "objectID": "team/alexandre-perera-lluna/index.html#former-phd-thesis",
    "href": "team/alexandre-perera-lluna/index.html#former-phd-thesis",
    "title": "Alexandre Perera Lluna",
    "section": "Former PhD Thesis",
    "text": "Former PhD Thesis\nI have proudly advised several PhD students who have successfully defended their dissertations:\n\nHelena Brunel. Genetic association analysis of complex diseases through information theoretic metrics and linear pleiotropy. Defended on 14/11/2013 at Universitat Politècnica de catalunya\nJorge Alberto Jaramillo Garzón. Protein function prediction with semi-supervised classification based on evolutionary multi-objective optimization, Defended on 25/11/2013 at the Universidad Nacional de Colombia. This thesis was coadvised with Dr. German Castellanos from the same university.\nAndrey Ziyatdinov, Biomimetic Setup for Chemosensor-Based Machine olfaction. Defended on 4/12/2014 at Universitat Politècnica de Catalunya.\nFrancesc Fernandez, Machine Learning Methods for the automated analysis of metabolomic data. Defended on 30/10/2014 at Universitat Politècnica de Catalunya.\nErola Pairó,Detection of Transcription Factor Binding Sites by Means of Multivariate Signal Processing Techniques. Defended on 21/07/2015 at Universitat de Barcelona. This thesis was coadvised with Dr. Santiago Marco from the same university.\nJoan Maynou, Computational representation and discovery of transcription factor binding sites. Defended on 01/02/2016 at Universitat Politècnica de Catalunya.\nXavier Domingo, Signal processing in Metabolomics”, Defended on July 2016. Coadvised with Prof. Jesús Brezmes, Universitat Rovira i Virgili.\nGiovana Gavidia,Study of Longitudinal Neurodegeneration Biomarkers to Support the Early Diagnosis of Alzheimer’s Disease. Defended on 20/03/2018 at Universitat Politècnica de Catalunya.\nSamir Kanaan.Multiview pattern recognition methods for data visualization, embedding and clustering. Defended on 22/09/2017 at Universitat Politècnica de Catalunya.\nSergio Picart, “Statistical Normalisation of Network Propagation Methods for Computational biology” , by Sergio Picart, 23/7,2020. The defense was performed online due to the sars-cov-2 pandemic and published in here.\nAngela López del Río, “Development And Improvement Of Computer Aided Drug Development Techniques Using Deep Learning Algorithms”, defended on June 23rd, 2021. currently Post-Doc Data Scientist at Boehringer Ingelheim."
  },
  {
    "objectID": "team/alexandre-perera-lluna/index.html#publications",
    "href": "team/alexandre-perera-lluna/index.html#publications",
    "title": "Alexandre Perera Lluna",
    "section": "Publications",
    "text": "Publications\nYou can also check my journal papers, available through:\n\npublications for all the group, or\ngoogle scholar.\n\nA possibly incomplete and malformatted list of publications is included below:\n\n2024\n\n\n1. Mediterranean diet is a predictor of progression of subclinical atherosclerosis in a mediterranean population: the ILERVAS prospective cohort studyRojo-L’opez, M. and Bermudez, M. and Castro, E. and Farras, C. and Torres, G. and Pamplona, R. and Lecube, A. and Valdivieso, J. and Fern’andez, E. and Julve, J. and Castelblanco, E. and Alonso, N. and Antentas, M. and Barranco, M. and Perera, A. and Franch, J. and Granado-Casas, M. and Mauricio Puente, D’idacNutrients, Vol. 16, Issue 21, article 3607 (2024)[DOI]\n\n\n2. Cerebrospinal fluid homovanillic and 5-hydroxyindoleacetic acids in a large pediatric population; establishment of reference intervals and impact of disease and medicationRodr’iguez, H. and Ormaz’abal, A. and Casado, M. and Arias, A. and Oliva, C. and Barranco, M. and Casadevall, R. and Garc’ia, F. and Nascimento, A. and Ortez, C. and Natera, D. and Armangu’e, T. and O’Callaghan, M. and Juli’a, N. and Darling, A. and Ortigoza, J. and Fons, C. and Garc’ia-Cazorla, ’A. and Perera, A. and Artuch, R.Clinical chemistry, Vol. 70, Issue 12 (2024)[DOI]\n\n\n3. Lipidome characterisation and sex-specific differences in type 1 and type 2 diabetes mellitusBarranco, M. and Alonso, N. and Weber, R. and Lloyd, G. and Hern’andez, M. and Yanes, ’O. and Capellades, J. and Jankevics, A. and Winder, C. and Falguera, M. and Franch, J. and Dunn, W. and Perera, A. and Castelblanco, E. and Mauricio Puente, D’idacCardiovascular diabetology, Vol. 23, Issue article 109 (2024)[DOI]\n\n\n4. Use of enzymatically converted cell-free DNA (cfDNA) data for copy number variation-linked fragmentation analysis allows for early colorectal cancer detectionCanal, P. and Perera, A.International journal of molecular sciences, Vol. 25, Issue 6, article 3502 (2024)[DOI]\n\n\n2023\n\n\n5. Intrinsic functional brain connectivity changes following aerobic exercise, computerized cognitive training, and their combination in physically inactive healthy late-middle-aged adults: the Projecte MovimentDimitriadis, S. and Castells, A. and Roig, F. and Dacosta, R. and Lamonja, N. and Toran, P. and Garc’ia, A. and Monte, G. and Stillman, C. and Perera, A. and Mataro-Serrat, M.GeroScience, Vol. 46, Issue (2023)[DOI]\n\n\n6. Home monitoring for older singles: A gas sensor array systemMar’in, D. and Llano, J. and Haddi, Z. and Perera, A. and Fonollosa, J.Sensors and actuators B. Chemical, Vol. 393, Issue article 134036 (2023)[DOI]\n\n\n7. EpiGe: A machine-learning strategy for rapid classification of medulloblastoma using PCR-based methyl-genotypingG’omez S. and Llano, J. and Garc’ia, M. and Garrido, A. and Sunol, M. and Lemos, I. and P’erez, S. and Salvador, N. and Gene, N. and Arnau, R. and Santa Mar’ia, V. and Perez, M. and Perera, A. and Mora, J. and Morales, A. and Lavarino, C.iScience, Vol. 26, Issue 9, article 107598 (2023)[DOI]\n\n\n2022\n\n\n8. Mapping layperson medical terminology into the Human Phenotype Ontology using neural machine translation modelsManzini, E. and Garrido, J. and Fonollosa, J. and Perera, A.Expert systems with applications, Vol. 204, Issue C (2022)[DOI]\n\n\n9. Longitudinal deep learning clustering of Type 2 Diabetes Mellitus trajectories using routinely collected health recordsManzini, E. and Vlacho, B. and Franch, J. and Escudero, J. and G’enova, A. and Reixach-Espaulella, E. and Andr’es, E. and Pizarro, I. and Portero, J. and Mauricio Puente, D’idac and Perera, A.Journal of biomedical informatics, Vol. 135, Issue Article 104218 (2022)[DOI]\n\n\n10. Data processing and analysis in mass spectrometry-based metabolomicsPeralbo, ’A. and Sola, P. and Perera, A. and Chicano, E.Methods in Molecular Biology, Vol. 2571, Issue (2022)[DOI]\n\n\n11. #CoronavirusCruise: Impact and implications of the COVID-19 outbreaks on the perception of cruise tourismHern’andez-Lara, A. and Abubakr, B. and Sanchez-Rebull, M. and Perera, A.Tourism Management Perspectives, Vol. 41, Issue (2022)[DOI]\n\n\n2021\n\n\n12. How did the COVID-19 lockdown affect children and adolescent’s well-being: Spanish parents, children, and adolescents respondAjanovic, S. and Garrido, J. and Baro, B. and Balanza, N. and Varo, R. and Millat-Mart’inez, P. and Arias, S. and Fonollosa, J. and Perera, A. and Jordan, I. and Munoz-Almagro, C. and Bonet-Carn’e, E. and Crosas-Soler, A. and Via, E. and Nafria, B. and Garc’ia-Garc’ia, J. and Bassat, Q.Frontiers in public health, Vol. 9, Issue 745062 (2021)[DOI]\n\n\n13. mWISE: an algorithm for context-based annotation of liquid chromatography-mass spectrometry features through diffusion in graphsBarranco, M. and Sola, P. and Picart, S. and Kanaan-Izquierdo, S. and Fonollosa, J. and Perera, A.Analytical chemistry, Vol. 93, Issue 31 (2021)[DOI]\n\n\n14. Accurate early-stage colorectal cancer detection through analysis of cell-free circulating tumor DNA (ctDNA) methylation patternsCanal, P. and Perera, A.Journal of clinical oncology, Vol. 39, Issue 15_suppl (2021)[DOI]\n\n\n15. Global collaborative social network (Share4Rare) to promote citizen science in rare disease research: Platform development studyRadu, R. and Hern’andez, S. and Borrega, O. and Palmeri, A. and Athanasiou, D. and Brooke, N. and Chap’i, I. and Le Corvec, A. and Guglieri, M. and Perera, A. and Garrido, J. and Ryll, B. and Nafria, B.JMIR formative research, Vol. 5, Issue 3 (2021)[DOI]\n\n\n16. MMP1 drives tumor progression in large cell carcinoma of the lung through fibroblast senescenceIkemori, R. and Llorente, A. and Maqueda, M. and D’avalos, A. and Perera, A. and Reguart, N. and Quiroz, L. and Alcaraz Casademunt, JordiCancer letters, Vol. 507, Issue (2021)[DOI]\n\n\n17. Balancing data on deep learning-based proteochemometric activity classificationLopez, A. and Picart, S. and Perera, A.Journal of chemical information and modeling, Vol. 61, Issue 4 (2021)[DOI]\n\n\n18. Game learning analytics of instant messaging and online discussion forums in higher educationHern’andez-Lara, A. and Perera, A. and Serradell-L’opez, E.Education and Training, Vol. 63, Issue 9 (2021)[DOI]\n\n\n2020\n\n\n19. MultiPaths: a Python framework for analyzing multi-layer biological networks using diffusion algorithmsMar’in-Lla’o, Josep, J. and Mubeen, S. and Perera, A. and Hofmann-Apitius, M. and Picart, S. and Domingo-Fern’andez, D.Bioinformatics, Vol. , Issue btaa1069 (2020)[DOI]\n\n\n20. The effect of statistical normalisation on network propagation scoresPicart, S. and Thompson, W. and Buil, A. and Perera, A.Bioinformatics, Vol. , Issue btaa896 (2020)[DOI]\n\n\n21. Effect of sequence padding on the performance of deep learning models in archaeal protein functional predictionLopez, A. and Martin, M. and Perera, A.Scientific reports, Vol. 10, Issue (2020)[DOI]\n\n\n22. Open chromatin region (OCR) based model predicts advanced adenoma in plasma cell-free DNA whole-genome bisulfite sequencing dataCanal, P. and Perera, A.Annals of oncology, Vol. 31, Issue S4 (2020)[DOI]\n\n\n23. Eye vergence responses during an attention task in adults with ADHD and clinical controlsJim’enez, E. and Avella, C. and Kustow, S. and Cubbin, S. and Corrales, M. and Richarte, V. and Esposito, F. and Morata, I. and Perera, A. and Varela, P.Journal of attention disorders, Vol. , Issue (2020)[DOI]\n\n\n2019\n\n\n24. Benchmarking network propagation methods for disease gene identificationPicart, S. and Barrett, S. and Will’e, D. and Perera, A. and Gutteridge, A. and Dessailly, B.PLoS computational biology, Vol. 15, Issue 9 (2019)[DOI]\n\n\n25. Effects and mechanisms of cognitive, aerobic exercise, and combined training on cognition, health, and brain outcomes in physically inactive older adults: the projecte moviment protocolCastells, A. and Roig, F. and Lamonja, N. and Perera, A.Frontiers in aging neuroscience, Vol. 11, Issue (2019)[DOI]\n\n\n26. Heart failure with preserved ejection fraction infrequently evolves toward a reduced phenotype in long-term survivors: a long-term prospective longitudinal studyLupon, J. and Gavidia, G. and de Antonio-Ferrer, M. and Perera, A. and L’opez-Ayerbe, J. and Domingo-Teixidor, M. and Nunez, J. and Zamora, E. and Moliner, P. and santiago-vacas, E. and Santemases, J. and Bay’es-Genis, A.Circulation-Heart Failure, Vol. 12, Issue e005652 (2019)[DOI]\n\n\n27. Amitriptyline at an environmentally relevant concentration alters the profile of metabolites beyond monoamines in gilt-head breamZiarrusta, H. and Ribbenstedt, A. and Mijangos, L. and Picart, S. and Perera, A. and Prieto, A. and Izagirre, U.Environmental toxicology and chemistry, Vol. , Issue (2019)[DOI]\n\n\n28. Evaluation of cross-validation strategies in sequence-based binding prediction using deep learningLopez, A. and Nonell, A. and Vidal, D. and Perera, A.Journal of chemical information and modeling, Vol. 58, Issue 4 (2019)[DOI]\n\n\n2018\n\n\n29. Multiview: a software package for multiview pattern recognition methodsKanaan-Izquierdo, S. and Ziyatdinov, A. and Burgueno, M. and Perera, A.Bioinformatics, Vol. , Issue bty1039 (2018)[DOI]\n\n\n30. FELLA: an R package to enrich metabolomics dataPicart, S. and Fernandez-Albert, F. and Vinaixa, M. and Yanes, ’O. and Perera, A.BMC bioinformatics, Vol. 19, Issue 1 (2018)[DOI]\n\n\n31. Dynamic trajectories of left ventricular ejection fraction in heart failureLupon, J. and Gavidia, G. and Ferrer, E. and de Antonio-Ferrer, M. and Perera, A. and D’iaz, P.Journal of the American College of Cardiology, Vol. 72, Issue (2018)[DOI]\n\n\n32. Non-targeted metabolomics reveals alterations in liver and plasma of gilt-head bream exposed to oxybenzoneZiarrusta, H. and Mijangos, L. and Picart, S. and Irazola, M. and Perera, A.Chemosphere, Vol. 211, Issue (2018)[DOI]\n\n\n33. Applying learning analytics to students’ interaction in business simulation games. The usefulness of learning analytics to know what students really learnHern’andez-Lara, A. and Perera, A. and Serradell-L’opez, E.Computers in human behavior, Vol. 92, Issue (2018)[DOI]\n\n\n34. Caminal, P. and Sola, F. and Gomis, P. and Guasch, E. and Perera, A. and Mont, L.European journal of applied physiology, Vol. 118, Issue 3 (2018)[DOI]\n\n\n35. diffuStats: an R package to compute diffusion-based scores on biological networksPicart, S. and Thompson, W. and Buil Demur, A. and Perera, A.Bioinformatics, Vol. 34, Issue 3 (2018)[DOI]\n\n\n36. Clinical validation of eye vergence as an objective marker for diagnosis of ADHD in childrenVarela, P. and Esposito, F. and Morata, I. and Capdevila, A. and Perera, A.Journal of attention disorders, Vol. , Issue (2018)[DOI]\n\n\n37. Multiview and multifeature spectral clustering using common eigenvectorsKanaan-Izquierdo, S. and Ziyatdinov, A. and Perera, A.Pattern recognition letters, Vol. 102, Issue (2018)[DOI]\n\n\n2017\n\n\n38. Null diffusion-based enrichment for metabolomics dataPicart, S. and Fernandez, F. and Vinaixa, M. and Rodr’iguez, M.A. and Aivio, S. and Stracker, T. and Yanes Torrado, ’Oscar and Perera, A.PloS one, Vol. 12, Issue (2017)[DOI]\n\n\n39. Assessment of heart rate variability during an endurance mountain trail race by multi-scale entropy analysisVallverdu, M. and Ruiz, A. and Roca, E. and Caminal, P. and Rodr’iguez, F. and Irurtia-Amigo, A. and Perera, A.Entropy (Basel), Vol. 19, Issue 12 (2017)[DOI]\n\n\n40. Affected pathways and transcriptional regulators in gene expression response to an ultra-marathon trail: Global and independent activity approachesMaqueda, M. and Roca, E. and Brotons, D. and Soria, J. and Perera, A.PloS one, Vol. 12, Issue 10 (2017)[DOI]\n\n\n41. Baitmet, a computational approach for GC-MS library-driven metabolite profilingDomingo, X. and Brezmes, J. and Venturini, G. and Viv’o-Truyols, G. and Perera, A. and Vinaixa, M.Metabolomics, Vol. 13, Issue 93 (2017)[DOI]\n\n\n42. Early prediction of Alzheimer’s disease using null longitudinal model-based classifiersGavidia, G. and Kanaan-Izquierdo, S. and Mataro-Serrat, M. and Perera, A.PloS one, Vol. 12, Issue 1 (2017)[DOI]\n\n\n2016\n\n\n43. The Central role of KNG1 gene as a genetic determinant of coagulation pathway-related traits: Exploring metaphenotypesBrunel, H. and Massanet, R. and Martinez, A. and Ziyatdinov, A. and Martin-Fernandez, L. and Souto, J. and Perera, A. and Soria, J.PloS one, Vol. 11, Issue 12 (2016)[DOI]\n\n\n44. Avoiding hard chromatographic segmentation: A moving window approach for the automated resolution of gas chromatography-mass spectrometry-based metabolomics signals by multivariate methodsDomingo, X. and Perera, A. and Brezmes, J.Journal of chromatography A, Vol. 1474, Issue (2016)[DOI]\n\n\n45. eRah: A Computational Tool Integrating Spectral Deconvolution and Alignment with Quantification and Identification of Metabolites in GC/MS-Based MetabolomicsDomingo, X. and Brezmes, J. and Vinaixa, M. and Samino, S. and Ramirez, N. and Ramon, M. and Lerin, C. and D’iaz, M. and Ibanez, L. and Correig, X. and Perera, A. and Yanes, ’O.Analytical chemistry, Vol. 88, Issue 19 (2016)[DOI]\n\n\n46. DNA methylation profiling unveils TGF-ss hyperresponse in tumor associated fibroblasts from lung cancer patientsVizioso, M. and Puig, M. and Carmona, F. and Maqueda, M. and Gomez, A. and Labernardie, N. and Gabasa, M. and Mendizuri, S. and Ikemori, R. and Trepat, X. and Moran, S. and Vidal, E. and Reguart, N. and Perera, A. and Esteller, M. and Alcaraz Casademunt, JordiCancer research, Vol. 76, Issue 14 Supplement (2016)[DOI]\n\n\n47. Automated resolution of chromatographic signals by independent component analysis-orthogonal signal deconvolution in comprehensive gas chromatography/mass spectrometry-based metabolomicsDomingo, X. and Perera, A. and Ramirez, N. and Brezmes, J.Computer methods and programs in biomedicine, Vol. 130, Issue (2016)[DOI]\n\n\n48. Applicability of semi-supervised learning assumptions for gene ontology terms predictionJaramillo-Garz’on, J. and Castellanos, C. and Perera, A.Revista Facultad de Ingenier’ia. Universidad de Antioqu’ia, Vol. , Issue 79 (2016)[DOI]\n\n\n49. Solarius: an R interface to SOLAR for variance component analysis in pedigreesZiyatdinov, A. and Brunel, H. and Martinez, A. and Buil, A. and Perera, A. and Soria, J.Bioinformatics, Vol. 32, Issue 12 (2016)[DOI]\n\n\n50. Clinical phenotype clustering in cardiovascular risk patients for the identification of responsive metabotypes after red wine polyphenol intakeVazquez, R. and Llorach, R. and Perera, A. and Mandal, R. and Feliz, M. and Tinahones, F. and Wishart, D. and Andres, C.Journal of nutritional biochemistry, Vol. 28, Issue (2016)[DOI]\n\n\n2015\n\n\n51. Aberrant DNA methylation in non-small cell lung cancer-associated fibroblastsVizoso, M. and Puig, M. and Carmona, F.J. and Maqueda, M. and Vel’asquez, A. and G’omez, A. and Labernadie, A. and Lugo, R. and Gabasa, M. and Rigat-Brugarolas, L. and Trepat, X. and Ramirez, J. and Moran, S. and Vidal, E. and Reguart, N. and Perera, A. and Esteller, M. and Alcaraz Casademunt, JordiCarcinogenesis, Vol. 36, Issue 12 (2015)[DOI]\n\n\n52. Sequence information gain based motif analysisMaynou, J. and Pair’o, E. and Marco, S. and Perera, A.BMC bioinformatics, Vol. 16, Issue 377 (2015)[DOI]\n\n\n53. Compound identification in gas chromatography/mass spectrometry-based metabolomics by blind source separationDomingo, X. and Perera, A. and Ramirez, N. and Canellas, N. and Correig, X. and Brezmes, J.Journal of chromatography A, Vol. 1409, Issue (2015)[DOI]\n\n\n54. Data set from gas sensor array under flow modulationZiyatdinov, A. and Fonollosa, J. and Fern’andez, L. and Guti’errez G’alvez, Agust’in and Marco, S. and Perera, A.Data in brief, Vol. 3, Issue (2015)[DOI]\n\n\n55. Synthetic benchmarks for machine olfaction: Classification, segmentation and sensor damageZiyatdinov, A. and Perera, A.Data in brief, Vol. 3, Issue (2015)[DOI]\n\n\n56. Bioinspired early detection through gas flow modulation in chemo-sensory systemsZiyatdinov, A. and Fonollosa, J. and Valentin-Fernandez, L. and Guti’errez G’alvez, Agust’in and Marco, S. and Perera, A.Sensors and actuators B. Chemical, Vol. 206, Issue (2015)[DOI]\n\n\n2014\n\n\n57. Intensity drift removal in LC/MS metabolomics by common variance compensationFernandez, F. and Llorach, R. and Garcia, M. and Ziyatdinov, A. and Andres, C. and Perera, A.Bioinformatics, Vol. 30, Issue 20 (2014)[DOI]\n\n\n58. Automatic capacitor bank identification in power distribution systemsPerera, A. and Manivannan, K. and Xu, P. and Gutierrez-Osuna, R. and Benner, C. and Russell, B.Electric power systems research, Vol. 111, Issue (2014)[DOI]\n\n\n59. An R package to analyse LC/MS metabolomic data: MAIT (Metabolite Automatic Identification Toolkit)Fernandez, F. and Llorach, R. and Andres, C. and Perera, A.Bioinformatics, Vol. 30, Issue 13 (2014)[DOI]\n\n\n60. Peak aggregation as an innovative strategy for improving the predictive power of LC-MS metabolomic profilesFernandez, F. and Llorach, R. and Andres, C. and Perera, A.Analytical chemistry, Vol. 86, Issue 5 (2014)[DOI]\n\n\n61. Data simulation in machine olfaction with the R package chemosensorsZiyatdinov, A. and Perera, A.PloS one, Vol. 9, Issue 2 (2014)[DOI]\n\n\n2013\n\n\n62. A biomimetic approach to machine olfaction, featuring a very large-scale chemical sensor array and embedded neuro-bio-inspired computationMarco, S. and Guti’errez G’alvez, Agust’in and Lansner, A. and Martinez, D. and Rospars, J.P. and Beccherelli, R. and Perera, A. and Pearce, T.C. and Verschure, P. and Persaud, K.C.Microsystem technologies, Vol. , Issue (2013)[DOI]\n\n\n63. Effect of genetic regions on the correlation between single point mutation variability and morbidityBrunel, H. and Gallardo, J. and Vallverdu, M. and Caminal, P. and Perera, A.Computers in biology and medicine, Vol. 43, Issue 5 (2013)[DOI]\n\n\n64. Predictability of gene ontology slim-terms from primary structure information in Embryophyta plant proteinsJaramillo-Garz’on, J. and Gallardo, J. and Castellanos, G. and Perera, A.BMC bioinformatics, Vol. 14, Issue 68 (2013)[DOI]\n\n\n65. A software tool for large-scale synthetic experiments based on polymeric sensor arraysZiyatdinov, A. and Fernandez, E. and Chaudry, A. and Marco, S. and Persaud, K.C. and Perera, A.Sensors and actuators B. Chemical, Vol. 177, Issue (2013)[DOI]\n\n\n2012\n\n\n66. Choi-Williams distribution to describe coding and non-coding regions in primary transcript pre-mRNAMelia U. and Vallverdu, M. and Claria, F and Gallardo, J. and Perera, A. and Caminal, P.Journal of Medical and Biological Engineering, Vol. , Issue (2012)[DOI]\n\n\n67. A subspace method for the detection of transcription factor binding sitesPair’o, E. and Maynou, J. and Marco, S. and Perera, A.Bioinformatics, Vol. 28, Issue 10 (2012)[DOI]\n\n\n2011\n\n\n68. Biologically inspired computation for chemical sensingFonollosa, J. and Gutierrez-Galvez, A. and Lansner, A. and Martinez, D. and Rospars, J.P. and Beccherelli, R. and Perera, A. and Pearce, T.C. and Vershure, P. and Persaud, K.C. and Marco, S.Procedia computer science, Vol. 7, Issue (2011)[DOI]\n\n\n2010\n\n\n69. MISS: a non-linear methodology based on mutual information for genetic association studies in both population and sib-pairs analysisBrunel, H. and Gallardo, J. and Buil, J. and Vallverdu, M. and Soria, J. and Caminal, P. and Perera, A.Bioinformatics, Vol. 26, Issue 15 (2010)[DOI]\n\n\n70. Evaluation of fish spoilage by means of a single metal oxide sensor under temperature modulationPerera, A. and Pardo, A. and Barrettino, D. and Hierlemann, A. and Marco, S.Sensors and actuators B. Chemical, Vol. 146, Issue 2 (2010)[DOI]\n\n\n71. Drift compensation of gas sensor array data by common principal component analysisZiyatdinov, A. and Marco, S. and Chaudry, A. and Persaud, K.C. and Caminal, P. and Perera, A.Sensors and actuators B. Chemical, Vol. 146, Issue 2 (2010)[DOI]\n\n\n72. Computational detection of transcription factor binding sites through differential R’enyi entropyMaynou, J. and Gallardo, J. and Vallverdu, M. and Caminal, P. and Perera, A.IEEE transactions on information theory, Vol. 52, Issue 2 (2010)[DOI]\n\n\n73. Drift compensation of gas sensor array data by Orthogonal Signal CorrectionPadilla, M. and Perera, A. and Montoliu, I. and Chaudry, A. and Persaud, K.C. and Marco, S.Chemometrics and intelligent laboratory systems, Vol. 100, Issue 1 (2010)[DOI]\n\n\n2009\n\n\n74. A new gene-based association test for genome-wide association studiesBuil Demur, A. and Mart’inez-P’erez, A. and Perera, A. and Rib, L. and Soria, J. and Caminal, P.BMC proceedings (Online), Vol. 15, Issue 3 (2009)[DOI]\n\n\n75. Dimensionality reduction oriented toward the feature visualization for ischemia detectionDelgado-Tejos, E. and Perera, A. and Vallverdu, M. and Caminal, P. and Castellanos Dominguez, G.IEEE transactions on information technology in biomedicine, Vol. 13, Issue 4 (2009)[DOI]\n\n\n2008\n\n\n76. DNA Binding Site Characterization by Means of R’enyi Entropy Measures on NucleotidePerera, A. and Vallverdu, M. and Claria, F and Caminal, P.IEEE transactions on nanobioscience, Vol. 7, Issue 2 (2008)[DOI]\n\n\n2007\n\n\n77. Searching for master regulators of transcription in a human gene expression data setBuil Demur, A. and Perera, A. and Souto, R. and Peralta, J. and Almasy, L. and Vallverdu, M. and Caminal, P. and Soria, J.BMC proceedings (Online), Vol. 1, Issue (Suppl 1) (2007)[DOI]\n\n\n78. Gene-phenotype association using mutual information-based cluster analysisBuil Demur, A. and Perera, A. and Brunel, H. and Souto, J. and Fontcuberta, J. and Vallverdu, M. and Soria, J. and Caminal, P.Genetic epidemiology, Vol. 31, Issue 6 (2007)[DOI]\n\n\n2006\n\n\n79. Gas measurement systems based on IEEE1451.2 standardPardo, A. and C’amara, L. and Cabr’e, J. and Perera, A. and Cano, X. and Marco, S. and Bosch, J.Sensors and actuators B. Chemical, Vol. 116, Issue 1-2 (2006)[DOI]\n\n\n80. A dimensionality-reduction technique inspired by receptor convergence in the olfactory systemPerera, A. and Yamanaka, T. and Guti’errez-G’alvez, A. and Gutierrez-Osuna, R. and Raman, B.Sensors and actuators B. Chemical, Vol. 116, Issue 1-2 (2006)[DOI]\n\n\n81. Feature extraction on three way enose signalsPadilla, M. and Montoliu, I. and Pardo, A. and Perera, A.Sensors and actuators B. Chemical, Vol. 116, Issue 1-2 (2006)[DOI]\n\n\n82. On-line novelty detection by recursive dynamic principal component analysis and gas sensor arrays under drift conditionsPerera, A. and Papamichail, N. and Barsan, N. and Weimar, U. and Marco, S.IEEE sensors journal, Vol. 6, Issue 3 (2006)[DOI]\n\n\n2002\n\n\n83. Fuzzy inference system for sensor array calibration : prediction of CO and CH4 levels in variable humidity conditionsTeodor, S. and Perera, A. and Pardo, A. and Hahn, S. and Marco, S. and Barsan, N. and Weimar, U.Chemometrics and intelligent laboratory systems, Vol. 64, Issue 2 (2002)[DOI]\n\n\n2001\n\n\n84. An intelligent detector based on temperature modulation of a gas sensor with a digital signal processorArturo, O. and Marco, S. and Perera, A. and Teodor, S. and Pardo, A. and Samitier, J.Sensors and actuators B. Chemical, Vol. 78, Issue 1-3 (2001)[DOI]\n\n\n2000\n\n\n85. A bio-inspired nonlinear algorithm to integrate carbon monoxide concentration aiming to fulfil international standardsPerera, A. and Teodor, S. and Marco, S.Sensors and actuators B. Chemical, Vol. 69, Issue 3 (2000)[DOI]\n\n\nUnknown Year\n\n\n86. Validity of the Polar V800 monitor for measuring heart rate variability in mountain running route conditions**, Vol. , Issue (Unknown)[DOI]\n\n\n87. **, Vol. , Issue (Unknown)[DOI]\n\n\n88. **, Vol. , Issue (Unknown)[DOI]"
  },
  {
    "objectID": "team/alexandre-perera-lluna/index.html#footnotes",
    "href": "team/alexandre-perera-lluna/index.html#footnotes",
    "title": "Alexandre Perera Lluna",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nsoon to defent her thesis↩︎"
  },
  {
    "objectID": "team/former.html#former-phd-students",
    "href": "team/former.html#former-phd-students",
    "title": "Fornmer Members Team",
    "section": "Former PhD Students",
    "text": "Former PhD Students\n\n\n\n\n\n\nSergi Picart Armada\n\n\nWelcome to my small site! My name is Sergi Picart and my background is Industrial Engineering and a Degree in Mathematics. I deeply thank CFIS (UPC, Barcelona, Spain) for offering me this excellent opportunity. I used to be a PhD student in Biomedical Engineering, advised by Alexandre Perera in the B2SLab. The defense took place virtually in Covid19 times and can be found here. You will find further information about the publications and the software in the sections below. I enjoy playing with math, statistical learning and programming. Likewise, computational biology is an amusing and rewarding field to explore. My main research topic included interpretable diffusion algorithms on biological networks, combined with functional analysis on metabolomics, transcriptomics and proteomics studies.\n\nhttp://b2slab.upc.edu/team/sergi-picart/",
    "crumbs": [
      "Our Team",
      "Former Members"
    ]
  },
  {
    "objectID": "team/former.html#former-students-working-in-a-master-thesis-or-degree-thesis-at-b2slab",
    "href": "team/former.html#former-students-working-in-a-master-thesis-or-degree-thesis-at-b2slab",
    "title": "Fornmer Members Team",
    "section": "former students working in a Master thesis or degree thesis at b2slab",
    "text": "former students working in a Master thesis or degree thesis at b2slab",
    "crumbs": [
      "Our Team",
      "Former Members"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About b2lsab",
    "section": "",
    "text": "Welcome to the Bioinformatics and Biomedical Signals Laboratory (B2SLab) at the Universitat Politècnica de Catalunya (UPC) in Barcelona, Spain. As a multidisciplinary research group within the Research Centre for Biomedical Engineering (CREB), we specialize in biomedical engineering, bioinformatics, machine learning, and statistics, leveraging over two decades of expertise in these fields. (xartecsalut.com)\nOur Mission\nAt B2SLab, our mission is to advance healthcare through innovative research and the development of cutting-edge technologies. We aim to bridge the gap between data science and biomedical applications, contributing to improved patient outcomes and a deeper understanding of complex biological systems.\nOur Team\n\nWho is who?.\nResearch Focus\nOur research encompasses a broad spectrum of areas, including:\n\nBiomedical Engineering: Developing novel solutions to complex medical challenges.\nBioinformatics: Analyzing and interpreting biological data to uncover new insights.\nMachine Learning and Statistics: Applying advanced computational techniques to model and predict biological phenomena.\n\nKey Projects and Tools\nWe are proud to have developed several impactful tools and projects:\n\nFELLA: An R package designed for the enrichment and interpretation of metabolomics data, facilitating the identification of affected pathways and biological functions. (FELLA)\ndiffuStats: An R package that computes and benchmarks diffusion scores on biological networks, aiding in the analysis of molecular interactions. (diffustats\nShare4Rare: A data science initiative aimed at supporting patients with rare diseases through collaborative research and information sharing. (share4rare)\n\nCollaborations and Community Engagement\nWe actively collaborate with various research networks and institutions to foster innovation and share knowledge. Our leadership in the coordination of projects like Xartec Salut underscores our commitment to advancing health technologies and contributing to the scientific community. (xartecsalut.com)\nConnect with Us\nStay updated on our latest research and developments by following us on Mastodon (sorry, we are not in –and will not register in– x/twitter): (Mastodon)\nFor more information about our projects, publications, and team members, please visit our official website: (b2slab.upc.edu)\nAt B2SLab, we are dedicated to pushing the boundaries of biomedical research and technology, striving to make meaningful contributions to science and society."
  },
  {
    "objectID": "about.html#goals",
    "href": "about.html#goals",
    "title": "About b2lsab",
    "section": "",
    "text": "Welcome to the Bioinformatics and Biomedical Signals Laboratory (B2SLab) at the Universitat Politècnica de Catalunya (UPC) in Barcelona, Spain. As a multidisciplinary research group within the Research Centre for Biomedical Engineering (CREB), we specialize in biomedical engineering, bioinformatics, machine learning, and statistics, leveraging over two decades of expertise in these fields. (xartecsalut.com)\nOur Mission\nAt B2SLab, our mission is to advance healthcare through innovative research and the development of cutting-edge technologies. We aim to bridge the gap between data science and biomedical applications, contributing to improved patient outcomes and a deeper understanding of complex biological systems.\nOur Team\n\nWho is who?.\nResearch Focus\nOur research encompasses a broad spectrum of areas, including:\n\nBiomedical Engineering: Developing novel solutions to complex medical challenges.\nBioinformatics: Analyzing and interpreting biological data to uncover new insights.\nMachine Learning and Statistics: Applying advanced computational techniques to model and predict biological phenomena.\n\nKey Projects and Tools\nWe are proud to have developed several impactful tools and projects:\n\nFELLA: An R package designed for the enrichment and interpretation of metabolomics data, facilitating the identification of affected pathways and biological functions. (FELLA)\ndiffuStats: An R package that computes and benchmarks diffusion scores on biological networks, aiding in the analysis of molecular interactions. (diffustats\nShare4Rare: A data science initiative aimed at supporting patients with rare diseases through collaborative research and information sharing. (share4rare)\n\nCollaborations and Community Engagement\nWe actively collaborate with various research networks and institutions to foster innovation and share knowledge. Our leadership in the coordination of projects like Xartec Salut underscores our commitment to advancing health technologies and contributing to the scientific community. (xartecsalut.com)\nConnect with Us\nStay updated on our latest research and developments by following us on Mastodon (sorry, we are not in –and will not register in– x/twitter): (Mastodon)\nFor more information about our projects, publications, and team members, please visit our official website: (b2slab.upc.edu)\nAt B2SLab, we are dedicated to pushing the boundaries of biomedical research and technology, striving to make meaningful contributions to science and society."
  },
  {
    "objectID": "about.html#help-us",
    "href": "about.html#help-us",
    "title": "About b2lsab",
    "section": "Help us",
    "text": "Help us\nYou can contribute to our research in many ways:\n\nBy using our resarch and software\nBy opening issues to provide feedback and share ideas.\nBy proposing collaborations and joining our lab"
  },
  {
    "objectID": "blog/posts/20240502_Berta/index.html",
    "href": "blog/posts/20240502_Berta/index.html",
    "title": "Does Physical Activity Impact On The Intellectual Performance Of Students?",
    "section": "",
    "text": "Does Physical Activity Impact On The Intellectual Performance Of Students?\n\n\n\nThe performance experienced by medicine in recent years could not be explained without the role of new technologies. Specifically, medical technologies have played an important role in understanding the mechanisms involved in the biological behaviour of the human body. Research, development and technological innovation become vital tools not only to improve the diagnosis and therapy of diseases, but also for improving the quality of life. Keep reading to learn B2SLab latest activities in physical activity research. In recent years, the hypothesis is debated whether physical activity stimulates intellectual performance of students. This hypothesis considers that exercise changes the neuronal communication by acting on the space of exchanging information, which affects the brain connectivity by modifying the structure and function of the nervous system. Researchers of the Biomedical Engineering Research Center CREB (Technical University of Catalonia UPC) want to bring our knowledge to the discussion of the previous hypothesis together with members of the Alliance for Biomedical Research and Technology (BERTA). This Alliance is formed by the Sant Joan de Déu Hospital, the CREB, the IBUB (Institute of Biomedicine, University of Barcelona) and the IR3C (Institute for Brain, Cognition and Behavior, University of Barcelona). The BERTA Alliance aims to develop projects where the child is the star. Within the field of health, the most important market is the adult, which focuses almost all innovations in the health sector. The pediatric sector requires customized solutions because they often cannot incorporate proposals conceived and designed for adults. We have initiated a project to assess the influence of physical exercise on intellectual performance of children. Specifically, the objectives of this project are: – To determine biomarkers of synaptic function, and to assess cognitive functions before, during and after physical activity, using electrophysiological testing. – To assess the kinetics of neuronal growth factors produced by exercise. – To analyse individual genetic variations that predispose to a greater cognitive benefit of exercise. – To study brain changes by neuroimaging analysis. The CREB provides to the project its knowledge on applied research, proposing new medical technology tools for the monitoring of physiological variables and the analysis of results. The Division of Bioengineering and Instrumentation will develop systems to monitor the body mass index, and the body composition, before and after the physical activity. The physical activity will be monitored using smartphones, to assess objectively the total daily activity levels in the children participating in the study. The Computer Graphics Division of the CREB will design a computer game that will automatically measure the attention of the children before and after the exercise. Researchers of this division have experience working with children as end-users, and have developed software to work on mobile devices. The Division of Biomedical Signals and Systems will participate in the integration and analysis of data using statistical methods, including: longitudinal analysis in consecutive measurements of biomarkers, training of nonlinear multivariate predictive models and integration of data from omics platforms. The results of this study could be used for recommending specific programs of physical training in schools, aimed at improving cognitive skills and academic performance of students."
  },
  {
    "objectID": "blog/posts/20250207_socialNetworks/index.html",
    "href": "blog/posts/20250207_socialNetworks/index.html",
    "title": "Follow us!",
    "section": "",
    "text": "Stay updated on our latest research and developments by following us on our social networks. We are present in the Fediverse. The Fediverse is a collection of interconnected social platforms communicating through a shared protocol called ActivityPub. This protocol allows users to interact seamlessly across different platforms.\n\nMastodon (sorry, we are not in –and will not register in– x/twitter):\nBluesky. This is our same profile in Mastodon, present on BLusky through the Sky Follower Bridge.\n\nFor more information about our projects, publications, and team members, please visit our official website: (b2slab.upc.edu)"
  },
  {
    "objectID": "blog/posts/20250207_socialNetworks/index.html#connect-with-us",
    "href": "blog/posts/20250207_socialNetworks/index.html#connect-with-us",
    "title": "Follow us!",
    "section": "",
    "text": "Stay updated on our latest research and developments by following us on our social networks. We are present in the Fediverse. The Fediverse is a collection of interconnected social platforms communicating through a shared protocol called ActivityPub. This protocol allows users to interact seamlessly across different platforms.\n\nMastodon (sorry, we are not in –and will not register in– x/twitter):\nBluesky. This is our same profile in Mastodon, present on BLusky through the Sky Follower Bridge.\n\nFor more information about our projects, publications, and team members, please visit our official website: (b2slab.upc.edu)"
  },
  {
    "objectID": "blog/posts/20140429_talkPere/index.html",
    "href": "blog/posts/20140429_talkPere/index.html",
    "title": "A Talk At FarmaIndustria By Dr. Caminal (Spanish)",
    "section": "",
    "text": "This video shows a talk by Pere Caminal (CREB-UPC); at FARMAINDUSTRIA  (provided by Vimeo), at VI Conferencia Anual de las Plataformas Tecnológicas de Investigación Biomédica: Medicamentos Innovadores, Nanomedicina Tecnología Sanitaria y Mercados Biotecnológicos Fomentando la Innovación en Salud. Madrid, 20 y 21 de Marzo de 2013\nCaminal, FarmaIndustria, talk"
  },
  {
    "objectID": "software/mait.html",
    "href": "software/mait.html",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "",
    "text": "MAIT is an R package to perform Metabolomic LC/MS analysis: MAIT (Metabolite Automatic Identification Toolkit), developed by Francesc Fernandez, Rafael Llorach, Cristina Andres-LaCueva and Alexandre Perera and it was published in Oxford Journals Bioinformatics. MAIT package is currently maintained by the B2SLab at UPC, so please send us a note if you have any suggestion or comment.\n\n\n\nFernández-Albert F., Llorach R., Andrés-Lacueva C., Perera-Lluna A. An R package to analyse LC/MS metabolomic data: MAIT (Metabolite Automatic Identification Toolkit. Bioinformatics (2014). doi: 10.1093/bioinformatics/btu136.\n\n\n\n\nMAIT is capable of peak Peak detection for metabolomic LC/MS data sets. It uses a matched filter (Danielsson, Bylund, and Markides 2002) and the centWave algorithm (Tautenhahn et al. 2008) through the XCMS package, developed by the SCRIPPS Center for Metabolomics.\nMAIT also uses further complementary steps in the peak annotation stage, also usingCAMERA package (Kuhl et al. 2011). The peaks within each peak group are annotated following a reference adduct/fragment table and a mass tolerance window. MAIT uses a predefined biotransformation table where the biotransformations to find are saved. A user-defined biotransformation table can be set as an input.\nThe package also holds a metabolite identification stage, in which a predefined metabolite database is mined to search for the significant masses, also using a tolerance window. This database is the Human Metabolome Database (HMDB) (Wishart, Knox, Guo, Eisner, Young, Gautam, Hau, Psychogios, Dong, Bouatra, and et al. 2009), 2009/07 version.\nIn terms of statistical tests, the package automatically tests on every feature and selects a significant set of features. Depending on the number of classes defined in the data, MAIT can use Student’s T-test, Welch’s T-tests and Mann-Whitney tests for two classes or ANOVA and Kruskal-Wallis tests for more than two classes. The use is able to define custom tests in the automatic procedure as well.\nA nice addition of the MAIT R package, is the support for peak aggregation techniques that might lead to better feature selection (Fernández-Albert, Llorach, Andrés-Lacueva, and Perera-Lluna), as defined in: Fernández-Albert F, Llorach R, Andrés-Lacueva C, Perera-Lluna A. Improvement in the predicting power of LC-MS-based metabolomics profiles by peak aggregation techniques. Analytical Chemistry 2014 86 (5), 2320-2325 DOI: 10.1021/ac403702p\n\n\n\nThe latest version of the MAIT package is available through the Bioconductor repository: - Package: MAIT - Tutorial: MAITSupplementary\nData of the faahKO package in zip format. This is the data used in the MAIT tutorial.\n\nWT class data\nKO class data\n\n\n\n\nThe data files for this example are a subset of the data used in reference (Saghatelian, Trauger, Want, Hawkins, Siuzdak, and Cravatt 2004), which are freely distributed through the faahKO package Smith (2012). In these data there are 2 classes of mice: a group where the fatty acid amide hydrolase gene has been suppressed (class knockout or KO) and a group of wild type mice (class wild type or WT). There are 6 spinal cord samples in each class. In the following, the MAIT package will be used to read and analyse these samples using the main functions discussed in Section 5. The significant features related to each class will be found using statistical tests and analysed through the different plots that MAIT produces.",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#citation",
    "href": "software/mait.html#citation",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "",
    "text": "Fernández-Albert F., Llorach R., Andrés-Lacueva C., Perera-Lluna A. An R package to analyse LC/MS metabolomic data: MAIT (Metabolite Automatic Identification Toolkit. Bioinformatics (2014). doi: 10.1093/bioinformatics/btu136.",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#mait-description",
    "href": "software/mait.html#mait-description",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "",
    "text": "MAIT is capable of peak Peak detection for metabolomic LC/MS data sets. It uses a matched filter (Danielsson, Bylund, and Markides 2002) and the centWave algorithm (Tautenhahn et al. 2008) through the XCMS package, developed by the SCRIPPS Center for Metabolomics.\nMAIT also uses further complementary steps in the peak annotation stage, also usingCAMERA package (Kuhl et al. 2011). The peaks within each peak group are annotated following a reference adduct/fragment table and a mass tolerance window. MAIT uses a predefined biotransformation table where the biotransformations to find are saved. A user-defined biotransformation table can be set as an input.\nThe package also holds a metabolite identification stage, in which a predefined metabolite database is mined to search for the significant masses, also using a tolerance window. This database is the Human Metabolome Database (HMDB) (Wishart, Knox, Guo, Eisner, Young, Gautam, Hau, Psychogios, Dong, Bouatra, and et al. 2009), 2009/07 version.\nIn terms of statistical tests, the package automatically tests on every feature and selects a significant set of features. Depending on the number of classes defined in the data, MAIT can use Student’s T-test, Welch’s T-tests and Mann-Whitney tests for two classes or ANOVA and Kruskal-Wallis tests for more than two classes. The use is able to define custom tests in the automatic procedure as well.\nA nice addition of the MAIT R package, is the support for peak aggregation techniques that might lead to better feature selection (Fernández-Albert, Llorach, Andrés-Lacueva, and Perera-Lluna), as defined in: Fernández-Albert F, Llorach R, Andrés-Lacueva C, Perera-Lluna A. Improvement in the predicting power of LC-MS-based metabolomics profiles by peak aggregation techniques. Analytical Chemistry 2014 86 (5), 2320-2325 DOI: 10.1021/ac403702p",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#downloading-mait",
    "href": "software/mait.html#downloading-mait",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "",
    "text": "The latest version of the MAIT package is available through the Bioconductor repository: - Package: MAIT - Tutorial: MAITSupplementary\nData of the faahKO package in zip format. This is the data used in the MAIT tutorial.\n\nWT class data\nKO class data",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#using-mait",
    "href": "software/mait.html#using-mait",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "",
    "text": "The data files for this example are a subset of the data used in reference (Saghatelian, Trauger, Want, Hawkins, Siuzdak, and Cravatt 2004), which are freely distributed through the faahKO package Smith (2012). In these data there are 2 classes of mice: a group where the fatty acid amide hydrolase gene has been suppressed (class knockout or KO) and a group of wild type mice (class wild type or WT). There are 6 spinal cord samples in each class. In the following, the MAIT package will be used to read and analyse these samples using the main functions discussed in Section 5. The significant features related to each class will be found using statistical tests and analysed through the different plots that MAIT produces.",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#peak-detection",
    "href": "software/mait.html#peak-detection",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "Peak Detection",
    "text": "Peak Detection\nPeak detection in metabolomic LC/MS datasets is complex, and several approaches have been developed. Two of the most well-established techniques are matched filter and centWave algorithm. MAIT can use both algorithms through the XCMS package.",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#peak-annotation",
    "href": "software/mait.html#peak-annotation",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "Peak Annotation",
    "text": "Peak Annotation\nThe MAIT package uses three complementary steps for peak annotation:\n\nStep 1: Uses a peak correlation distance approach and a retention time window to determine peaks from the same metabolite.\nStep 2: Uses a mass tolerance window to detect specific mass losses (biotransformations) based on a predefined table.\nStep 3: Performs a metabolite identification stage using the Human Metabolome Database (HMDB).",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#statistical-analysis",
    "href": "software/mait.html#statistical-analysis",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "Statistical Analysis",
    "text": "Statistical Analysis\nThe goal of metabolomic profiling is to obtain statistically significant features that contain class-related information. MAIT applies standard univariate statistical tests (ANOVA or t-test) and selects significant features based on a user-defined P-value threshold. A validation test quantifies how well data classes are separated through repeated random sub-sampling cross-validation using:\n\nPartial Least Squares - Discriminant Analysis (PLS-DA)\nSupport Vector Machine (SVM) with a radial kernel\nK-Nearest Neighbors (KNN)",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#data-import",
    "href": "software/mait.html#data-import",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "Data Import",
    "text": "Data Import\nData files should be placed in directories named after their respective classes. The MAIT package requires class folders within a single directory.",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#peak-detection-1",
    "href": "software/mait.html#peak-detection-1",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "Peak Detection",
    "text": "Peak Detection\nOnce the data is organized, peak detection can be initiated using the sampleProcessing() function:\n\nlibrary(MAIT)\nlibrary(faahKO)\ncdfFiles &lt;- system.file(\"cdf\", package=\"faahKO\", mustWork=TRUE)\nMAIT &lt;- sampleProcessing(dataDir = cdfFiles, project = \"MAIT_Demo\", snThres=2, rtStep=0.03)",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#peak-annotation-1",
    "href": "software/mait.html#peak-annotation-1",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "Peak Annotation",
    "text": "Peak Annotation\nThe next step in the data processing is the first peak annotation step, which is per- formed through the peakAnnotation(). If the input parameter adductTable is not set, then the default MAIT table for positive polarisation will be selected. However, if the adductTable parameter is set to ”negAdducts”, the default MAIT table for negative fragments will be chosen instead. peakAnnotation function also creates an output table (see Table 3) containing the peak mass (in charge/mass units), the retention time (in minutes) and the spectral ID number for all the peaks detected. A call of the function peakAnnotation may be:\n\nMAIT &lt;- peakAnnotation(MAIT.object = MAIT, corrWithSamp = 0.7, corrBetSamp = 0.75, perfwhm = 0.6)\n\nBecause the parameter adductTable was not set in the peakAnnotation call, a warning was shown informing that the default MAIT table for positive polarisation mode was selected. The xsAnnotated object that contains all the information related to peaks, spectra and their annotation is stored in the MAIT object.\nFowing the first peak annotation stage, we want to know which features are different be- tween classes. Consequently, we run the function spectralSigFeatures().\n\nMAIT&lt;-spectralSigFeatures(MAIT.object = MAIT, pvalue = 0.05, p.adj = \"none\",\nscale = FALSE)\n\nIt is worth mentioning that by setting the scale parameter to TRUE, the data will be scaled to have unit variance. The parameter p.adj allows for using the multiple testing correction methods included in the function p.adjust of the package stats. A summary of the statis- tically significant features is created and saved in a table called significantFeatures.csv (see Table 3). It is placed inside the Tables subfolder located in the project folder. This table shows characteristics of the statistically significant features, such as their P-value, the peak annotation or the expression of the peaks across samples. This table can be retrieved at any time from the MAIT-class objects by typing the instruction:\n\nsignTable &lt;- sigPeaksTable(MAIT.object = MAIT, printCSVfile = FALSE)\n\nThe number of significant features can be retrieved from the MAIT-class object as follows:\n\nMAIT\n\nBy default, when using two classes, the statistical test applied by MAIT is the Welch’s test. Nevertheless, when having two classes,MAIT also supports applying the Student’s t-test and the non-parametric test Mann-Whitney test",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#statistical-analysis-1",
    "href": "software/mait.html#statistical-analysis-1",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "Statistical Analysis",
    "text": "Statistical Analysis\nTo identify statistically significant features:\n\nMAIT &lt;- spectralSigFeatures(MAIT.object = MAIT, pvalue=0.05, p.adj=\"none\", scale=FALSE)\nsummary(MAIT)",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#statistical-plots",
    "href": "software/mait.html#statistical-plots",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "Statistical Plots",
    "text": "Statistical Plots\nOut of 2,402 features, 106 were found to be statistically significant. At this point, several MAIT functions can be used to extract and visualise the results of the analysis. Functions plotBoxplot, plotHeatmap, plotPCA and plotPLS automatically generate boxplots, heat maps PCA score plot and PLS score plot files in the project folder when they are applied to a MAIT object.\n\nplotBoxplot(MAIT)\nplotHeatmap(MAIT)\nMAIT &lt;- plotPCA(MAIT, plot3d=FALSE)\nMAIT &lt;- plotPLS(MAIT, plot3d=FALSE)\n\nThe plotPCA and plotPLS functions produce MAIT objects with the corresponding PCA and PLS models saved inside. The models, loadings and scores can be retrieved from the MAIT objects by using the functions model, loadings and scores.\nAll the output figures are saved in their corresponding subfolders contained in the project folder. The names of the folders for the boxplots, heat maps and score plots are Boxplots, Heatmaps, PCA Scoreplots and PLS Scoreplots respectively. Figures 3 and 4 depict a heat map, a PCA score plot and a PLS score plot created when functions plotHeatmap, plotPCA and plotPLS were launched.",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#biotransformations",
    "href": "software/mait.html#biotransformations",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "Biotransformations",
    "text": "Biotransformations\nBefore identifying the metabolites, peak annotation can be improved using the function Biotransformations to make interpreting the results easier. The MAIT package uses a default biotransformations table, but another table can be defined by the user and introduced by using the bioTable function input variable. The biotransformations table that MAIT uses is saved inside the file MAITtables.RData, under the name biotransformationsTable.\n\nMAIT &lt;- Biotransformations(MAIT.object = MAIT, peakPrecision = 0.005)",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#metabolite-identification",
    "href": "software/mait.html#metabolite-identification",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "Metabolite Identification",
    "text": "Metabolite Identification\nOnce the biotransformations annotation step is finished, the significant features have been enriched with a more specific annotation. The annotation procedure performed by the Biotransformations() function never replaces the peak annotations already done by other functions. MAIT considers the peak annotations to be complementary; therefore, when new annotations are detected, they are added to the current peak annotation and the identifica- tion function may be launched to identify the metabolites corresponding to the statistically significant features in the data.\n\nMAIT &lt;- identifyMetabolites(MAIT.object = MAIT, peakTolerance = 0.005)\n\nBy default, the function identifyMetabolites() looks for the peaks of the significant fea- tures in the MAIT default metabolite database. The input parameter peakTolerance defines the tolerance between the peak and a database compound to be considered a possible match. It is set to 0.005 mass/charge units by default. The argument polarity, refers to to the polar- ity in which the samples were taken (positive or negative). It is set to “positive” by default but it should be adjusted changed to ”negative” if the samples were recorded in negative po- larisation mode. To check the results easily, function identifyMetabolites creates a table containing the significant feature characteristics and the possible metabolite identifications.",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/mait.html#validation",
    "href": "software/mait.html#validation",
    "title": "MAIT Metabolite Automatic Identification Toolkit",
    "section": "Validation",
    "text": "Validation\nFinally, we will use the function Validation() to check the predictive value of the significant features. All the information related to the output of the Validation() function is saved in the project directory in a folder called “Validation”.\n\nMAIT &lt;- Validation(Iterations = 20, trainSamples = 3, MAIT.object = MAIT)\nsummary(MAIT)",
    "crumbs": [
      "Software",
      "MAIT"
    ]
  },
  {
    "objectID": "software/rtcorr.html",
    "href": "software/rtcorr.html",
    "title": "rtcorr",
    "section": "",
    "text": "The HCor package provides a set of functions for processing Liquid Chromatography-Mass Spectrometry (LC/MS) data, focusing on chromatogram drift correction, peak detection, and data normalization. It is designed to handle mass spectrometry chromatograms by adjusting retention times, correcting peak drift, and generating corrected chromatographic data.\n\n\n\nThe package consists of various functions aimed at correcting chromatographic drifts, handling chromatographic files, and processing raw LC/MS data. Below are the core functionalities:\n\n\n\nfiles2Matrix(): Reads chromatographic data from external files (e.g., mzXML, CDF) and converts them into a matrix format.\nprintCDFfile(): Writes corrected chromatographic data to new CDF files.\ncdfFileCreator(): Generates CDF files from processed chromatographic data.\n\n\n\n\n\ncorrDrift(): Applies drift correction to raw chromatographic data by fitting a hyperbolic model to compensate for retention time shifts.\npeakDrift(): Computes peak drift for a given chromatographic peak and corrects retention time variability.\npeakDrifts(): Applies peakDrift() to multiple peaks for batch correction.\n\n\n\n\n\nsetAnchorPeaks(): Selects anchor peaks for drift correction by allowing users to visually choose retention time intervals.\nsquares(): Computes the sum of squares of deviations to optimize drift correction parameters.\n\n\n\n\n\npeakDrifts(): Computes drift corrections across multiple peaks and generates corrected chromatographic datasets.\ncdfFileCreator(): Outputs corrected chromatographic data to CDF files.\n\n\n\n\n\n\n\nLoad the package and input data (e.g., mzXML files).\nConvert chromatographic data into a matrix format (files2Matrix).\nCorrect chromatographic drift by detecting and correcting peak shifts (corrDrift, peakDrift).\nOptimize retention time alignment (squares function minimizes drift errors).\nGenerate corrected chromatographic files for further analysis (printCDFfile, cdfFileCreator).\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(HCor)\n\n\n\n# Convert mzXML chromatograms to matrix format\ndataMatrix &lt;- files2Matrix(dataDir = \"path/to/mzXML/files\")\n\n# Set anchor peaks for drift correction\nanchorPeaks &lt;- setAnchorPeaks(dataMatrix, nAnchorPeaks = 3)\n\n# Compute drift correction\ncorrectedData &lt;- corrDrift(chromatogramsMatrix = dataMatrix, peakDriftsList = anchorPeaks)\n\n# Save corrected data as CDF files\ncdfFileCreator(dataMatrix = correctedData, dir2print = \"corrected_chromatograms\", dataDir = \"path/to/output\")\n\n\n\n\n\n\nDownload compressed files for Retention Time Drift Correction in LC/MS: HCor_1.01.tar.gz\n\n\n\n\nThe HCor package is a powerful tool for handling chromatographic drift correction in LC/MS data, allowing researchers to correct retention time shifts, improve peak detection, and generate normalized chromatographic files. 🚀",
    "crumbs": [
      "Software",
      "Retention Time Correction in LC/MS"
    ]
  },
  {
    "objectID": "software/rtcorr.html#key-functionalities",
    "href": "software/rtcorr.html#key-functionalities",
    "title": "rtcorr",
    "section": "",
    "text": "The package consists of various functions aimed at correcting chromatographic drifts, handling chromatographic files, and processing raw LC/MS data. Below are the core functionalities:\n\n\n\nfiles2Matrix(): Reads chromatographic data from external files (e.g., mzXML, CDF) and converts them into a matrix format.\nprintCDFfile(): Writes corrected chromatographic data to new CDF files.\ncdfFileCreator(): Generates CDF files from processed chromatographic data.\n\n\n\n\n\ncorrDrift(): Applies drift correction to raw chromatographic data by fitting a hyperbolic model to compensate for retention time shifts.\npeakDrift(): Computes peak drift for a given chromatographic peak and corrects retention time variability.\npeakDrifts(): Applies peakDrift() to multiple peaks for batch correction.\n\n\n\n\n\nsetAnchorPeaks(): Selects anchor peaks for drift correction by allowing users to visually choose retention time intervals.\nsquares(): Computes the sum of squares of deviations to optimize drift correction parameters.\n\n\n\n\n\npeakDrifts(): Computes drift corrections across multiple peaks and generates corrected chromatographic datasets.\ncdfFileCreator(): Outputs corrected chromatographic data to CDF files.",
    "crumbs": [
      "Software",
      "Retention Time Correction in LC/MS"
    ]
  },
  {
    "objectID": "software/rtcorr.html#how-hcor-works",
    "href": "software/rtcorr.html#how-hcor-works",
    "title": "rtcorr",
    "section": "",
    "text": "Load the package and input data (e.g., mzXML files).\nConvert chromatographic data into a matrix format (files2Matrix).\nCorrect chromatographic drift by detecting and correcting peak shifts (corrDrift, peakDrift).\nOptimize retention time alignment (squares function minimizes drift errors).\nGenerate corrected chromatographic files for further analysis (printCDFfile, cdfFileCreator).",
    "crumbs": [
      "Software",
      "Retention Time Correction in LC/MS"
    ]
  },
  {
    "objectID": "software/rtcorr.html#use-case-correcting-drift-in-lcms-data",
    "href": "software/rtcorr.html#use-case-correcting-drift-in-lcms-data",
    "title": "rtcorr",
    "section": "",
    "text": "# Load necessary libraries\nlibrary(HCor)\n\n\n\n# Convert mzXML chromatograms to matrix format\ndataMatrix &lt;- files2Matrix(dataDir = \"path/to/mzXML/files\")\n\n# Set anchor peaks for drift correction\nanchorPeaks &lt;- setAnchorPeaks(dataMatrix, nAnchorPeaks = 3)\n\n# Compute drift correction\ncorrectedData &lt;- corrDrift(chromatogramsMatrix = dataMatrix, peakDriftsList = anchorPeaks)\n\n# Save corrected data as CDF files\ncdfFileCreator(dataMatrix = correctedData, dir2print = \"corrected_chromatograms\", dataDir = \"path/to/output\")",
    "crumbs": [
      "Software",
      "Retention Time Correction in LC/MS"
    ]
  },
  {
    "objectID": "software/rtcorr.html#download",
    "href": "software/rtcorr.html#download",
    "title": "rtcorr",
    "section": "",
    "text": "Download compressed files for Retention Time Drift Correction in LC/MS: HCor_1.01.tar.gz",
    "crumbs": [
      "Software",
      "Retention Time Correction in LC/MS"
    ]
  },
  {
    "objectID": "software/rtcorr.html#conclusion",
    "href": "software/rtcorr.html#conclusion",
    "title": "rtcorr",
    "section": "",
    "text": "The HCor package is a powerful tool for handling chromatographic drift correction in LC/MS data, allowing researchers to correct retention time shifts, improve peak detection, and generate normalized chromatographic files. 🚀",
    "crumbs": [
      "Software",
      "Retention Time Correction in LC/MS"
    ]
  },
  {
    "objectID": "software/index.html",
    "href": "software/index.html",
    "title": "Reproducible Research",
    "section": "",
    "text": "At b2slab, we are committed to advancing open science, reproducible research, and collaborative development in computational biology, bioinformatics, and data science. We believe that scientific progress should be transparent, verifiable, and accessible to all.\nOur lab focuses on developing open-source tools, sharing data, and creating reproducible workflows to drive discoveries in health, biomedical engineering, and computational modeling. By leveraging open science principles, we ensure that our work can be used, extended, and improved by researchers worldwide.",
    "crumbs": [
      "Software",
      "Reproducible Research"
    ]
  },
  {
    "objectID": "software/index.html#philosophy-open-science-reproducibility",
    "href": "software/index.html#philosophy-open-science-reproducibility",
    "title": "Reproducible Research",
    "section": "Philosophy: Open Science & Reproducibility",
    "text": "Philosophy: Open Science & Reproducibility\nOur guiding principles include:\n\nOpen-Source Development : All our software, code, and methodologies are publicly available under open licenses to encourage collaboration. Reproducible Science: We emphasize best practices in version control, containerized environments, and well-documented pipelines to ensure that results can be independently verified.\nFAIR Data Principles : Our datasets follow the Findable, Accessible, Interoperable, and Reusable (FAIR) framework, promoting transparency and usability. Community-Driven Research: We actively contribute to and collaborate with global open-source communities, scientific repositories, and interdisciplinary research teams.",
    "crumbs": [
      "Software",
      "Reproducible Research"
    ]
  },
  {
    "objectID": "software/multiview.html",
    "href": "software/multiview.html",
    "title": "multiview",
    "section": "",
    "text": "The multiview package provides multiview methods to work with multiview data (datasets with several data matrices from the same samples). It contains methods for multiview dimensionality reduction and methods for multiview clustering.\n\n\nGiven a multiview dataset with v input data matrices, multiview dimensionality reduction methods produce a single, low-dimensional projection of the input data samples, trying to mantain as much of the original information as possible.\nPackage multiview offers the function mvmds to perform multiview dimensionality reduction in a similar way than the multidimensional scaling method (cmdscale).\nAnother dimensionality reduction function in this package is mvtsne, that extends tsne to multiview data.\n\n\n\nGiven a multiview dataset with v input data matrices, multiview clustering methods produce a single clustering assignment, considering the information from all the input views. Package multiview offers the function mvsc to perform multiview spectral clustering. It is an extension to spectral clustering (specc) to multiview datasets.",
    "crumbs": [
      "Software",
      "multiview "
    ]
  },
  {
    "objectID": "software/multiview.html#multiview-dimensionality-reduction",
    "href": "software/multiview.html#multiview-dimensionality-reduction",
    "title": "multiview",
    "section": "",
    "text": "Given a multiview dataset with v input data matrices, multiview dimensionality reduction methods produce a single, low-dimensional projection of the input data samples, trying to mantain as much of the original information as possible.\nPackage multiview offers the function mvmds to perform multiview dimensionality reduction in a similar way than the multidimensional scaling method (cmdscale).\nAnother dimensionality reduction function in this package is mvtsne, that extends tsne to multiview data.",
    "crumbs": [
      "Software",
      "multiview "
    ]
  },
  {
    "objectID": "software/multiview.html#multiview-clustering",
    "href": "software/multiview.html#multiview-clustering",
    "title": "multiview",
    "section": "",
    "text": "Given a multiview dataset with v input data matrices, multiview clustering methods produce a single clustering assignment, considering the information from all the input views. Package multiview offers the function mvsc to perform multiview spectral clustering. It is an extension to spectral clustering (specc) to multiview datasets.",
    "crumbs": [
      "Software",
      "multiview "
    ]
  },
  {
    "objectID": "software/multiview.html#what-is-multiview-data",
    "href": "software/multiview.html#what-is-multiview-data",
    "title": "multiview",
    "section": "What is multiview data?",
    "text": "What is multiview data?\nMultiview data are datasets that comprise two or more data matrices on the same population. This is usually the case when several experiments or measurements have been performed on the same subjects. Examples of multiview datasets are:\n\nA medical dataset that includes clinical history data, genetic expression data and medical imaging data from the same subjects.\nA text corpus with the same documents translated to several languages (each language is a data view).\nA scientific article dataset with two data views: the words of each document and a graph with the references between them.\nAn image dataset with different features extracted from the same input images (color histograms, different image descriptors, the raw pixels, and so on).\nA dataset of images and associated description tags written by their authors.\n\nMultimodal and multifeature data are special cases of multiview data.\nThe goal of this package is to provide the community multiview methods that take advantage of the existence of several data views to improve the quality of the analysis.",
    "crumbs": [
      "Software",
      "multiview "
    ]
  },
  {
    "objectID": "software/multiview.html#multiview-dimensionality-reduction-1",
    "href": "software/multiview.html#multiview-dimensionality-reduction-1",
    "title": "multiview",
    "section": "Multiview dimensionality reduction",
    "text": "Multiview dimensionality reduction\nGiven a multiview dataset with v input data matrices, multiview dimensionality reduction methods produce a single, low-dimensional projection of the input data samples, trying to mantain as much of the original information as possible. Package multiview offers the function mvmds to perform multiview dimensionality reduction in a similar way than the multidimensional scaling method (stats:cmdscale). Also, function mvtsne performs multiview dimensionality reduction, mostly suited for data visualization, in a similar way than the tSNE method (tsne::tsne).",
    "crumbs": [
      "Software",
      "multiview "
    ]
  },
  {
    "objectID": "software/multiview.html#multiview-clustering-1",
    "href": "software/multiview.html#multiview-clustering-1",
    "title": "multiview",
    "section": "Multiview clustering",
    "text": "Multiview clustering\nGiven a multiview dataset with v input data matrices, multiview clustering methods produce a single clustering assignment, considering the information from all the input views. Package multiview offers the function mvsc to perform multiview spectral clustering. It is an extension to spectral clustering (kernlab::specc) to multiview datasets.",
    "crumbs": [
      "Software",
      "multiview "
    ]
  },
  {
    "objectID": "software/multiview.html#multiview-multidimensional-scaling",
    "href": "software/multiview.html#multiview-multidimensional-scaling",
    "title": "multiview",
    "section": "Multiview multidimensional scaling",
    "text": "Multiview multidimensional scaling\nMultidimensional scaling (MDS) (Kruskal 1964) is a well-known dimensionality reduction method. Although there exist several variants of this method, multiview MDS method proposed here follows the structure of the “classical” MDS. The overall structure of the algorithm is as follows, where k is the desired dimensionality of the output space:\n\nCompute the distance matrices of the input matrices (when necessary).\nDouble-center (by rows and columns) the distance matrices.\nCompute the common eigenvectors of the previous matrices. Return the k eigenvectors with highest eigenvalues as the output space.\n\nThe common eigenvectors are computed using an algorithm derived from the algorithm proposed in (Trendafilov 2010).\n\nUsage\nThe mvmds function that implements the multiview multidimensional scaling method offers a simple interface, very similar to the single-view counterpart function cmdscale. First, instead of a single matrix of data to project, it requires a list of matrices. A list of matrices is used instead of a 3D matrix because the input matrices can have different number of columns. Moreover some or all of the input views may be dist objects. The other parameter is the desired number of dimensions of the output space, which defaults to 2.\nThe following example uses the handwritten digits dataset1, that contains 2,000 handwritten digits from 0 to 9. There are 200 digits of each value, hence the definition of the vector of sample classes.\nSix different feature sets are extracted from the digits images and provided in the dataset. From these, the next example uses four: the original pixels, the Fourier coefficients, the profile correlations and 6 morphological features. Then, mvmds is applied to these four data views in order to obtain a consistent low-dimensional representation of the digits that can be plotted.\n\nlibrary(multiview)\nfourier  &lt;- read.table(\"digits_data/mfeat-fou.txt\", header=FALSE, sep=\"\")\nprofcorr &lt;- read.table(\"digits_data/mfeat-fac.txt\", header=FALSE, sep=\"\")\npixels   &lt;- read.table(\"digits_data/mfeat-pix.txt\", header=FALSE, sep=\"\")\nmorpho   &lt;- read.table(\"digits_data/mfeat-mor.txt\", header=FALSE, sep=\"\")\n\nclasses &lt;- as.vector(sapply(0:9, function(x) rep(x,200)))\n\nprojection &lt;- mvmds(list(fourier, profcorr, pixels, morpho), k=2)\n\nmypalette &lt;- c(\"chartreuse\", \"blueviolet\", \"deeppink1\", \"cyan2\", \"black\", \"blue3\", \n              \"gold1\", \"seagreen1\", \"gray60\", \"red\")\nplot(projection[,1:2], col = mypalette[classes+1], \n    pch = as.character(classes), axes = FALSE,  xlab=\"\", ylab=\"\")\n\n\n\n\n\n\n\n\nAs the example shows, mvmds simply requires the input views in a list as the first parameter and the desired dimensionality of the output space. Matrices and dist objects can be freely mixed in the list of input views.",
    "crumbs": [
      "Software",
      "multiview "
    ]
  },
  {
    "objectID": "software/multiview.html#multiview-t-stochastic-neighbour-embedding",
    "href": "software/multiview.html#multiview-t-stochastic-neighbour-embedding",
    "title": "multiview",
    "section": "Multiview t-stochastic neighbour embedding",
    "text": "Multiview t-stochastic neighbour embedding\nt-distributed stochastic neighbour embedding (t-SNE) [Van Der Maaten, Hinton, and Maaten (2008); maaten2008visualizing; maaten2010] is a dimensionality reduction technique oriented to the generation of 2 and 3 dimensional representations of data, so they can be used to visualize the data. Multiview t-SNE is a multiview extension of t-SNE that generates a single low-dimensional representation of several input views. Like the original t-SNE method, multiview t-SNE is a method designed to generate embeddings of low dimensionality, typically 2 or 3, for example for data visualization.\nGiven a dataset with n data samples and v data views, the overall steps of this method are:\n\nFor each input data view, compute a n x n probability matrix. The ij value in these matrices are computed based on the distance from point i to point j, according to a Gaussian probability distribution.\nCombine the previous probability matrices into a single probability matrix P using expert opinion pooling theory, more specifically the log-linear formulation described in (Abbas 2009) and the weight assignment proposed in (Carvalho and Larson 2012).\nRandomly generate an initial projection of the data points.\nUse gradient descent optimization to adjust the neighbourhood probability matrix of the data projection to the probability matrix P.\n\n\nUsage\nThe mvtsne function of this package accepts, in its simplest form, two parameters: a list of input views and the number of dimensions of the desired output space. The input views can be either feature matrices or dist objects (or a mix of both). In any case, the number of samples in all input views has to be the same, although the number of features can be different. mvtsne returns the low-dimensional embedding as well as the weight assigned to each input view.\nA basic usage example, with the same handwritten digits dataset described above, is presented next:\n\nlibrary(multiview)\nfourier  &lt;- read.table(\"digits_data/mfeat-fou.txt\", header=FALSE, sep=\"\")\nprofcorr &lt;- read.table(\"digits_data/mfeat-fac.txt\", header=FALSE, sep=\"\")\npixels   &lt;- read.table(\"digits_data/mfeat-pix.txt\", header=FALSE, sep=\"\")\nmorpho   &lt;- read.table(\"digits_data/mfeat-mor.txt\", header=FALSE, sep=\"\")\n\nclasses &lt;- as.vector(sapply(0:9, function(x) rep(x,200)))\n\nprojection &lt;- mvtsne(list(fourier, profcorr, pixels, morpho), k=2)\n\nmypalette &lt;- c(\"chartreuse\", \"blueviolet\", \"deeppink1\", \"cyan2\", \"black\", \"blue3\", \n              \"gold1\", \"seagreen1\", \"gray60\", \"red\")\n\nplot(projection$embedding, col = mypalette[classes+1], \n    pch = as.character(classes), axes = FALSE,  xlab=\"\", ylab=\"\")\n\nThe remaining parameters of mvtsne allow a fine adjustment of the method and they are equivalent to those in tsne::tsne.",
    "crumbs": [
      "Software",
      "multiview "
    ]
  },
  {
    "objectID": "software/multiview.html#multiview-spectral-clustering",
    "href": "software/multiview.html#multiview-spectral-clustering",
    "title": "multiview",
    "section": "Multiview spectral clustering",
    "text": "Multiview spectral clustering\nSpectral clustering (Shi and Malik 2005), (Ng, Jordan, and Weiss 2001) is a well known clustering method whose distinctive feature is that it is capable of finding non-convex clusters, as it produces partitions of connected points. This is remarkably different from most classical clustering methods like k-means, that cluster points by distance, regardless of the topology and cohesion of the groups.\nPackage multiview includes a multiview spectral clustering method, available through function mvsc. A summarized description of the method follows:\n\nA Gaussian radial basis function is applied to the input samples for each input matrix. This produces a n x n matrix for each input view.\nThe symmetrical Laplacian matrix of the previous matrices is computed.\nUsing (Trendafilov 2010), the k first common eigenvectors of the Laplacian matrices are computed. This produces an n x k matrix that represents a clustering-oriented projection of the input data.\nK-means (a robust configuration) is applied to the previous matrix and the resulting clustering assignment is returned.\n\n\nUsage\nFunction mvsc first parameter is a list of input views, which can be either standard matrices (interpreted as sample/feature matrices) or dist objects, or a mix of both. All input views must be complete, i.e. they must have the same number of samples. The other mandatory parameter is k, an integer that controls the number of clusters produced. An example using the handwritten digits dataset described above follows:\n\nlibrary(multiview)\nfourier  &lt;- read.table(\"digits_data/mfeat-fou.txt\", header=FALSE, sep=\"\")\nprofcorr &lt;- read.table(\"digits_data/mfeat-fac.txt\", header=FALSE, sep=\"\")\npixels   &lt;- read.table(\"digits_data/mfeat-pix.txt\", header=FALSE, sep=\"\")\nmorpho   &lt;- read.table(\"digits_data/mfeat-mor.txt\", header=FALSE, sep=\"\")\n\nclasses &lt;- as.vector(sapply(0:9, function(x) rep(x,200)))\n\nclust   &lt;- mvsc(list(fourier, profcorr, pixels, morpho), k=10)\n\n# $clustering member has the clustering assignment vector\nknitr::kable(table(classes, clust$clustering))\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n0\n1\n0\n0\n0\n0\n0\n181\n18\n0\n0\n\n\n1\n0\n0\n0\n4\n2\n3\n0\n1\n1\n189\n\n\n2\n1\n195\n1\n3\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n4\n178\n0\n0\n5\n0\n0\n10\n3\n\n\n4\n2\n0\n0\n0\n1\n0\n0\n0\n195\n2\n\n\n5\n186\n1\n8\n0\n0\n0\n0\n0\n5\n0\n\n\n6\n2\n0\n0\n0\n188\n1\n0\n7\n0\n2\n\n\n7\n0\n5\n0\n38\n0\n154\n0\n0\n1\n2\n\n\n8\n0\n0\n0\n0\n0\n0\n4\n190\n0\n6\n\n\n9\n3\n0\n1\n182\n0\n3\n0\n6\n1\n4\n\n\n\n\n\nNote that the numbers assigned to each cluster are arbitrary, that is why they do not match with the original class labels. However, given the different numbering, the previous example shows the coincidence between the data classes and the clusters found.\nmvsc provides two parameters to fine-tune the clustering produced. First, parameter sigmas allows to specify the \\(\\sigma\\) parameter of the Gaussian radial basis function applied to the input views. This parameter can either be a vector of real values, with the \\(\\sigma\\) to use on each input view, or a single real value, meaning the same \\(\\sigma\\) will be used on all views.\nHowever, it can be difficult to estimate a proper value for \\(\\sigma\\). Therefore, a more intuitive parameter is provided, neighbours, which ultimately controls the \\(\\sigma\\) values used. This parameter usually is a single integer number specifying the average number of neighbours estimated for each data sample. Higher values cause more compact data projections, while lower values produce spread away projections. The practical consequences for clustering vary. Using too high values may end up merging different clusters, while using too low values may produce isolated islands of points, disconnected from their main cluster. Parameter neighbours can also be a vector of integers, where each value is respectively used on each input view. In general this option is not recommended, as the intrinsic structure of the data should be the same across the different views and a single neighbours value should suit all the input views.\nFollowing the previous example, neighbours adjustment can be used to improve the results:\n\nclust   &lt;- mvsc(list(fourier, profcorr, pixels, morpho), k=10, neighbours=2)\n\n# $clustering member has the clustering assignment vector\nknitr::kable(table(classes, clust$clustering))\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n190\n10\n0\n\n\n1\n0\n1\n6\n192\n0\n0\n0\n0\n0\n1\n\n\n2\n0\n2\n1\n0\n197\n0\n0\n0\n0\n0\n\n\n3\n0\n1\n3\n8\n3\n2\n181\n0\n0\n2\n\n\n4\n0\n0\n0\n2\n0\n6\n0\n0\n0\n192\n\n\n5\n0\n0\n0\n0\n1\n191\n5\n0\n0\n3\n\n\n6\n183\n0\n0\n2\n0\n0\n0\n0\n14\n1\n\n\n7\n0\n25\n170\n1\n4\n0\n0\n0\n0\n0\n\n\n8\n0\n0\n0\n7\n0\n0\n0\n2\n191\n0\n\n\n9\n0\n183\n0\n5\n0\n7\n0\n0\n4\n1\n\n\n\n\n\nAs the latter table shows, there is a better coincidence between each class and each cluster obtained. This parameter is ignored if sigmas is different from NULL.\nIf neither sigmas nor neighbours are given, then mvsc estimates the \\(\\sigma\\) of each input view using the heuristic proposed in (Planck and Luxburg 2006), i.e. as the average distance to the \\(\\log n\\)-th neighbour.\nFinally, parameter clustering allows the user to omit the final clustering phase (step 4 of the algorithm), and making mvsc return only the data projection computed.",
    "crumbs": [
      "Software",
      "multiview "
    ]
  },
  {
    "objectID": "software/multiview.html#footnotes",
    "href": "software/multiview.html#footnotes",
    "title": "multiview",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://archive.ics.uci.edu/ml/datasets/Multiple+Features↩︎",
    "crumbs": [
      "Software",
      "multiview "
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the b2slab",
    "section": "",
    "text": "This is a research group member of the Institut de Recerca i Innovació en Salut (IRIS) of the Universitat Politècnica de Catalunya (UPC) in Barcelona, Spain. Former member of the Research Center for Biomedical Engineering (CREB)\nOur main three research lines are : - Analysis of large datasets from primary and non-primary care related datasets. - Methods in Bioinformatics, specially in metabolomics - Biomedical Engineering\nThe Bioinformatics and Biomedical Signals Laboratory (B2SLab) at the Universitat Politècnica de Catalunya (UPC) focuses on the intersection of bioinformatics and biomedical signal processing. Our research encompasses areas such as computational modeling, machine learning, and data analysis applied to biological and medical data.\nCheck:\nOur publications Our Team\n\n\n\n\n\n\nData Science\n\n\n\n\nBioinformatics\n\n\n\n\nBioengineering\n\n\n\n\n\nThe study titled “A Deep Attention-Based Encoder for the Prediction of Type 2 Diabetes Longitudinal Outcomes from Routinely Collected Health Care Data” introduces DARE (Diabetic Attention with Relative position Representation Encoder), a transformer-based model designed to analyze longitudinal and heterogeneous data of Type 2 Diabetes Mellitus (T2DM) patients. Leveraging data from over 200,000 diabetic individuals in the SIDIAP primary healthcare database, which includes diagnostic codes, medication records, and various clinical measurements, DARE underwent an unsupervised pre-training phase followed by fine-tuning for three specific clinical prediction tasks:\nPredicting the occurrence of comorbidities. Assessing the achievement of target glycemic control (defined as glycated hemoglobin &lt; 7%). Forecasting changes in glucose-lowering treatments. In cross-validation, DARE demonstrated superior performance compared to baseline models, achieving area under the curve (AUC) scores of 0.88 for comorbidity prediction, 0.91 for treatment prediction, and 0.82 for HbA1c target prediction. These findings suggest that attention-based encoders like DARE can effectively model complex relationships in longitudinal T2DM data, potentially aiding clinicians in personalized disease management strategies.\n\n\n\n\n\n\n\n\n\n\n\n\nThe study titled “mWISE: An Algorithm for Context-Based Annotation of Liquid Chromatography–Mass Spectrometry Features through Diffusion in Graphs” introduces mWISE, an R package designed to enhance the annotation of LC–MS data in untargeted metabolomics. Traditional annotation methods often face challenges due to the complexity and volume of data generated in metabolomics studies. mWISE addresses these challenges by employing a context-based approach that utilizes diffusion in graphs to improve the accuracy and efficiency of feature annotation. This method allows for a more comprehensive understanding of the metabolome by effectively integrating various data sources and contextual information.\n\n\n\n\n\n\n\nThis study explores the feasibility of using gas sensor arrays for unobtrusive home monitoring of elderly individuals living alone. Unlike traditional monitoring systems, such as cameras or motion sensors, gas sensors provide a non-invasive and privacy-preserving alternative by detecting changes in air composition associated with human activities. The researchers developed a wireless sensor unit incorporating metal oxide gas sensors, carbon dioxide sensors, carbon monoxide sensors, and temperature-humidity sensors, which was deployed in an elderly person’s home for three months. The system continuously monitored the indoor air environment and used Principal Component Analysis (PCA) and statistical anomaly detection to extract activity patterns while compensating for environmental drift. The findings confirmed that gas sensors effectively captured daily routines and detected deviations—such as a Christmas Eve family gathering—demonstrating their ability to monitor Activities of Daily Living (ADLs) and recognize anomalies that could indicate emergencies or changes in well-being.\n\n\nCompared to motion sensors, the gas sensor system offered broader coverage without blind spots, as changes in air composition spread throughout the living space. The correlation between gas sensor data and motion sensor recordings validated its effectiveness. However, some limitations were noted, including delayed event detection due to air dispersion and the need for multiple sensor nodes for room-specific monitoring. The study suggests that integrating gas sensors into IoT-based smart home systems could enhance elderly care by providing real-time activity tracking, anomaly detection, and early warning signals to caregivers and family members. Future research should focus on improving spatial resolution, refining machine learning models for predictive analysis, and combining gas sensors with other smart home technologies to create a more robust, adaptive, and personalized home monitoring solution."
  },
  {
    "objectID": "index.html#bioinformatics-and-biomedical-signals-laboratory",
    "href": "index.html#bioinformatics-and-biomedical-signals-laboratory",
    "title": "Welcome to the b2slab",
    "section": "",
    "text": "This is a research group member of the Institut de Recerca i Innovació en Salut (IRIS) of the Universitat Politècnica de Catalunya (UPC) in Barcelona, Spain. Former member of the Research Center for Biomedical Engineering (CREB)\nOur main three research lines are : - Analysis of large datasets from primary and non-primary care related datasets. - Methods in Bioinformatics, specially in metabolomics - Biomedical Engineering\nThe Bioinformatics and Biomedical Signals Laboratory (B2SLab) at the Universitat Politècnica de Catalunya (UPC) focuses on the intersection of bioinformatics and biomedical signal processing. Our research encompasses areas such as computational modeling, machine learning, and data analysis applied to biological and medical data.\nCheck:\nOur publications Our Team"
  },
  {
    "objectID": "index.html#use-cases",
    "href": "index.html#use-cases",
    "title": "Welcome to the b2slab",
    "section": "",
    "text": "Data Science\n\n\n\n\nBioinformatics\n\n\n\n\nBioengineering\n\n\n\n\n\nThe study titled “A Deep Attention-Based Encoder for the Prediction of Type 2 Diabetes Longitudinal Outcomes from Routinely Collected Health Care Data” introduces DARE (Diabetic Attention with Relative position Representation Encoder), a transformer-based model designed to analyze longitudinal and heterogeneous data of Type 2 Diabetes Mellitus (T2DM) patients. Leveraging data from over 200,000 diabetic individuals in the SIDIAP primary healthcare database, which includes diagnostic codes, medication records, and various clinical measurements, DARE underwent an unsupervised pre-training phase followed by fine-tuning for three specific clinical prediction tasks:\nPredicting the occurrence of comorbidities. Assessing the achievement of target glycemic control (defined as glycated hemoglobin &lt; 7%). Forecasting changes in glucose-lowering treatments. In cross-validation, DARE demonstrated superior performance compared to baseline models, achieving area under the curve (AUC) scores of 0.88 for comorbidity prediction, 0.91 for treatment prediction, and 0.82 for HbA1c target prediction. These findings suggest that attention-based encoders like DARE can effectively model complex relationships in longitudinal T2DM data, potentially aiding clinicians in personalized disease management strategies.\n\n\n\n\n\n\n\n\n\n\n\n\nThe study titled “mWISE: An Algorithm for Context-Based Annotation of Liquid Chromatography–Mass Spectrometry Features through Diffusion in Graphs” introduces mWISE, an R package designed to enhance the annotation of LC–MS data in untargeted metabolomics. Traditional annotation methods often face challenges due to the complexity and volume of data generated in metabolomics studies. mWISE addresses these challenges by employing a context-based approach that utilizes diffusion in graphs to improve the accuracy and efficiency of feature annotation. This method allows for a more comprehensive understanding of the metabolome by effectively integrating various data sources and contextual information.\n\n\n\n\n\n\n\nThis study explores the feasibility of using gas sensor arrays for unobtrusive home monitoring of elderly individuals living alone. Unlike traditional monitoring systems, such as cameras or motion sensors, gas sensors provide a non-invasive and privacy-preserving alternative by detecting changes in air composition associated with human activities. The researchers developed a wireless sensor unit incorporating metal oxide gas sensors, carbon dioxide sensors, carbon monoxide sensors, and temperature-humidity sensors, which was deployed in an elderly person’s home for three months. The system continuously monitored the indoor air environment and used Principal Component Analysis (PCA) and statistical anomaly detection to extract activity patterns while compensating for environmental drift. The findings confirmed that gas sensors effectively captured daily routines and detected deviations—such as a Christmas Eve family gathering—demonstrating their ability to monitor Activities of Daily Living (ADLs) and recognize anomalies that could indicate emergencies or changes in well-being.\n\n\nCompared to motion sensors, the gas sensor system offered broader coverage without blind spots, as changes in air composition spread throughout the living space. The correlation between gas sensor data and motion sensor recordings validated its effectiveness. However, some limitations were noted, including delayed event detection due to air dispersion and the need for multiple sensor nodes for room-specific monitoring. The study suggests that integrating gas sensors into IoT-based smart home systems could enhance elderly care by providing real-time activity tracking, anomaly detection, and early warning signals to caregivers and family members. Future research should focus on improving spatial resolution, refining machine learning models for predictive analysis, and combining gas sensors with other smart home technologies to create a more robust, adaptive, and personalized home monitoring solution."
  },
  {
    "objectID": "trademark.html",
    "href": "trademark.html",
    "title": "Trademark Policy",
    "section": "",
    "text": "This policy is adapted directly from the Quarto and WordPress Foundation’s trademark policy for the Quarto project, WordPress and WordCamp names and logos. We admire the job that WordPress and Quarto has done building a thriving open source community while at the same time making possible a wide variety of WordPress related businesses. We hope that this policy will help us do the same for b2slab."
  },
  {
    "objectID": "trademark.html#goals",
    "href": "trademark.html#goals",
    "title": "Trademark Policy",
    "section": "Goals",
    "text": "Goals\nb2slab owns and oversees the trademark for the b2slab name and logo.\nPermission from b2slab is required to use the b2slab name or logo as part of any project, product, service, domain name, or company name.\nWe will grant permission to use the b2slab name and logo for projects that meet the following criteria:\n\nThe primary purpose of your project is to promote the spread and improvement of the b2slab software.\nYour project is non-commercial in nature (it can make money to cover its costs or contribute to non-profit entities, but it cannot be run as a for-profit project or business).\nYour project neither promotes nor is associated with entities that currently fail to comply with the open source license under which b2slab is distributed.\n\nIf your project meets these criteria, you will be permitted to use the b2slab name and logo to promote your project in any way you see fit with these exceptions: (1) Please do not use b2slab as part of a domain name; and (2) We do not allow the use of the trademark in advertising, including AdSense/AdWords.\nAll other b2slab-related businesses or projects can use the b2slab name and logo to refer to and explain their services, but they cannot use them as part of a product, project, service, domain name, or company name and they cannot use them in any way that suggests an affiliation with or endorsement by the b2slab open source project."
  },
  {
    "objectID": "trademark.html#examples",
    "href": "trademark.html#examples",
    "title": "Trademark Policy",
    "section": "Examples",
    "text": "Examples\nA consulting company can describe its business as “123 Publishing Services, offering b2slab consulting for publishers,” but cannot call its business “The b2slab Consulting Company.” Similarly, a business related to b2slab extensions can describe itself as “XYZ Extensions, the world’s best b2slab extensions,” but cannot call itself “The b2slab Extension Portal.”\nSimilarly, it’s OK to use the b2slab logo as part of a page that describes your products or services, but it is not OK to use it as part of your company or product logo or branding itself. Under no circumstances is it permitted to use b2slab as part of a domain name or top-level domain name.\nWhen in doubt about your use of the b2slab name or logo, please contact Posit at permissions@b2slab for clarification."
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Research Group Publications",
    "section": "",
    "text": "You can get the full list of activity of the group at Futur. The main list of publications is as follows1:"
  },
  {
    "objectID": "publications/index.html#footnotes",
    "href": "publications/index.html#footnotes",
    "title": "Research Group Publications",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPlease excuse us the issues in formatting, the list is computationally generated from RIS files listed at http↩︎"
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "Open Source License",
    "section": "",
    "text": "Each open source package published in this site includes its licensing scheme. If it is not included in the package the defult licence is GNU GPL v3.\nWe are using these tools to build this website. We include here the list of software used and its license.\nQuarto version 1.3 (and earlier) is licensed under the GNU GPL v2. Quarto version 1.4 is licensed under the MIT License. We believe that it’s better for everyone if the tools used for research and science are free and open. Reproducibility, widespread sharing of knowledge and techniques, and the leveling of the playing field by eliminating cost barriers are but a few of the shared benefits of free software in science.\nThe Quarto source code is available at https://github.com/quarto-dev/\nQuarto is a registered trademark of Posit. Please see our trademark policy for guidelines on usage of the Quarto trademark.\nQuarto also makes use of several other open-source projects, the distribution of which is subject to their respective licenses. Major components and their licenses include:\n\n\n\n\nProject\nLicense\n\n\n\n\nPandoc\nGNU GPL v2\n\n\nBootstrap 5\nMIT\n\n\nBootswatch 5\nMIT\n\n\nDeno\nMIT\n\n\nesbuild\nMIT\n\n\nDart Sass\nMIT\n\n\nObservable Runtime\nISC\n\n\nTypst\nApache License 2.0\n\n\nJuice\nMIT\n\n\n\nThank you for reading this :) - Àlex"
  },
  {
    "objectID": "open-positions/index.html",
    "href": "open-positions/index.html",
    "title": "Open Positions",
    "section": "",
    "text": "This are open positions"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Projects"
  },
  {
    "objectID": "R/animation/Untitled.html",
    "href": "R/animation/Untitled.html",
    "title": "b2slab",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom scipy.spatial import KDTree\nimport cv2\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom scipy.spatial import KDTree\nimport cv2\n\n# Load the logo as a color image\nlogo_path = \"b2slab.png\"\nlogo_img = cv2.imread(logo_path, cv2.IMREAD_COLOR)  # Load in BGR color\nlogo_img = cv2.flip(logo_img, 0)  # Flip vertically to correct orientation\nlogo_img = cv2.resize(logo_img, (200, 200))  # Resize for processing\n\n# Extract non-white pixels (keep only important logo details)\nmask = np.all(logo_img &lt; [230, 230, 230], axis=-1)  # Avoid white background\ny_indices, x_indices = np.where(mask)\n\n# Extract corresponding colors (convert BGR to RGB)\ncolors = logo_img[y_indices, x_indices][:, ::-1] / 255.0  # Normalize RGB colors\n\n# Convert (x, y) coordinates into a NumPy array\nlogo_points = np.vstack((x_indices, y_indices)).T\n\n# Normalize logo points for scaling\nlogo_points = logo_points - np.mean(logo_points, axis=0)  # Center the points\nlogo_points = logo_points / np.max(np.abs(logo_points), axis=0)  # Normalize to [-1, 1]\n\n# Generate initial random points and random colors\nnum_points = len(logo_points)\nrandom_points = np.random.uniform(-1, 1, (num_points, 2))\nrandom_colors = np.random.rand(num_points, 3)  # Random initial colors\n\n# KDTree for nearest neighbor movement\nlogo_tree = KDTree(logo_points)\n\n# Initialize figure\nfig, ax = plt.subplots()\nscat = ax.scatter(random_points[:, 0], random_points[:, 1], c=random_colors, s=2)\n\n# Update function for animation\ndef update(frame):\n    global random_points, random_colors\n    _, nearest_idx = logo_tree.query(random_points)\n    target_positions = logo_points[nearest_idx]\n    target_colors = colors[nearest_idx]\n\n    # Move points towards their target positions\n    random_points += (target_positions - random_points) * 0.05  # Adjust speed factor\n\n    # Gradually transition colors\n    random_colors += (target_colors - random_colors) * 0.1\n\n    # Update scatter plot\n    scat.set_offsets(random_points)\n    scat.set_facecolors(random_colors)\n    return scat,\n\n# Create animation\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.axis(\"off\")\n\nani = animation.FuncAnimation(fig, update, frames=100, interval=50, blit=False)\n\n# Save animation as a video\nani.save(\"b2sanim.mp4\", fps=30, dpi=200)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom scipy.spatial import KDTree\nimport cv2\nimport time\n\n# Load the logo as a color image\nlogo_path = \"b2slab.png\"\nlogo_img = cv2.imread(logo_path, cv2.IMREAD_COLOR)  # Load in BGR color\nlogo_img = cv2.flip(logo_img, 0)  # Flip vertically to correct orientation\nlogo_img = cv2.resize(logo_img, (200, 200))  # Resize for processing\n\n# Extract non-white pixels (keep only important logo details)\nmask = np.all(logo_img &lt; [230, 230, 230], axis=-1)  # Avoid white background\ny_indices, x_indices = np.where(mask)\n\n# Extract corresponding colors (convert BGR to RGB)\ncolors = logo_img[y_indices, x_indices][:, ::-1] / 255.0  # Normalize RGB colors\n\n# Convert (x, y) coordinates into a NumPy array\nlogo_points = np.vstack((x_indices, y_indices)).T\n\n# Normalize logo points for scaling\nlogo_points = logo_points - np.mean(logo_points, axis=0)  # Center the points\nlogo_points = logo_points / np.max(np.abs(logo_points), axis=0)  # Normalize to [-1, 1]\n\n# Generate initial random points and random colors\nnum_points = len(logo_points)\nrandom_points = np.random.uniform(-1, 1, (num_points, 2))\nrandom_colors = np.random.rand(num_points, 3)  # Random initial colors\n\n# Create shuffled versions of the logo positions\nshuffled_logo_1 = logo_points[np.random.permutation(num_points)]\nshuffled_logo_2 = logo_points[np.random.permutation(num_points)]\n\n# KDTree for nearest neighbor movement\nlogo_tree = KDTree(logo_points)\n\n# Animation States\nstate = 0  # 0 = random, 1 = logo, 2 = shuffled_1, 3 = shuffled_2, then repeat\nstate_duration = 50  # Number of frames each phase lasts\npause_duration = 10  # Number of frames to hold the logo\ncurrent_step = 0\n\n# Initialize figure\nfig, ax = plt.subplots()\nscat = ax.scatter(random_points[:, 0], random_points[:, 1], c=random_colors, s=2)\n\n# Smooth transition control\ndef smooth_curve(t):\n    \"\"\" Creates an ease-in-out effect for movement \"\"\"\n    return 3 * t**2 - 2 * t**3  # Sigmoid-like smooth step function\n\n# Update function for animation\ndef update(frame):\n    global random_points, random_colors, state, current_step\n\n    # Determine target positions based on state\n    if state == 0:\n        target_positions = random_points  # Stay random\n    elif state == 1:\n        target_positions = logo_points  # Move to the logo\n    elif state == 2:\n        target_positions = shuffled_logo_1  # Move to shuffled logo\n    elif state == 3:\n        target_positions = shuffled_logo_2  # Move to another shuffled version\n    \n    # Compute movement factor\n    t = smooth_curve(current_step / state_duration)\n    random_points += (target_positions - random_points) * 0.05  # Smooth movement\n    random_points += np.random.uniform(-0.005, 0.005, random_points.shape)  # Small jitter effect\n\n    # Gradually transition colors\n    target_colors = colors if state != 0 else np.random.rand(num_points, 3)\n    random_colors += (target_colors - random_colors) * 0.1\n\n    # Update scatter plot\n    scat.set_offsets(random_points)\n    scat.set_facecolors(random_colors)\n\n    # Manage state transitions\n    current_step += 1\n    if current_step &gt;= state_duration:\n        if state == 1 and current_step &gt;= state_duration + pause_duration:\n            state = 2  # Move to shuffled_1\n            current_step = 0\n        elif state == 2:\n            state = 3  # Move to shuffled_2\n            current_step = 0\n        elif state == 3:\n            state = 0  # Back to random\n            current_step = 0\n        else:\n            state = 1  # Move to the logo\n            current_step = 0\n\n    return scat,\n\n# Create animation\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.axis(\"off\")\n\nani = animation.FuncAnimation(fig, update, frames=500, interval=50, blit=False)\n\n# Save animation as a video\nani.save(\"b2s_cycle_animation.mp4\", fps=30, dpi=200)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n%%javascript\ndisplay(&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;B²S Lab Logo Animation&lt;/title&gt;\n    &lt;script src=\"https://d3js.org/d3.v6.min.js\"&gt;&lt;/script&gt;\n    &lt;style&gt;\n        body {\n            background-color: black;\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            height: 100vh;\n            overflow: hidden;\n        }\n        svg {\n            width: 800px;\n            height: 600px;\n        }\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;svg&gt;&lt;/svg&gt;\n\n    &lt;script&gt;\n        const width = 800;\n        const height = 600;\n        const numParticles = 1000; // Adjust for performance\n        const states = [\"random\", \"logo\", \"shuffle1\", \"shuffle2\"];\n        let currentState = 0;\n\n        const svg = d3.select(\"svg\");\n\n        // Load the image and extract pixel data\n        const img = new Image();\n        img.src = \"b2slab.png\";  // Ensure this is in the same folder\n        img.crossOrigin = \"Anonymous\";\n\n        img.onload = function () {\n            const canvas = document.createElement(\"canvas\");\n            canvas.width = 200;\n            canvas.height = 200;\n            const ctx = canvas.getContext(\"2d\");\n            ctx.drawImage(img, 0, 0, 200, 200);\n            const imageData = ctx.getImageData(0, 0, 200, 200).data;\n\n            let logoPoints = [];\n            let shuffled1 = [];\n            let shuffled2 = [];\n\n            // Extract non-white pixels and their colors\n            for (let y = 0; y &lt; 200; y++) {\n                for (let x = 0; x &lt; 200; x++) {\n                    const index = (y * 200 + x) * 4;\n                    const r = imageData[index];\n                    const g = imageData[index + 1];\n                    const b = imageData[index + 2];\n                    if (r &lt; 230 && g &lt; 230 && b &lt; 230) { // Ignore white pixels\n                        logoPoints.push({ x, y, color: `rgb(${r},${g},${b})` });\n                    }\n                }\n            }\n\n            // Normalize coordinates to fit SVG\n            logoPoints = logoPoints.map(p =&gt; ({\n                x: (p.x / 200) * width,\n                y: (p.y / 200) * height,\n                color: p.color\n            }));\n\n            shuffled1 = d3.shuffle([...logoPoints]);\n            shuffled2 = d3.shuffle([...logoPoints]);\n\n            // Generate random starting positions\n            let particles = d3.range(logoPoints.length).map(() =&gt; ({\n                x: Math.random() * width,\n                y: Math.random() * height,\n                targetX: Math.random() * width,\n                targetY: Math.random() * height,\n                color: \"white\"\n            }));\n\n            // Create SVG circles\n            const circles = svg.selectAll(\"circle\")\n                .data(particles)\n                .enter()\n                .append(\"circle\")\n                .attr(\"cx\", d =&gt; d.x)\n                .attr(\"cy\", d =&gt; d.y)\n                .attr(\"r\", 2)\n                .attr(\"fill\", d =&gt; d.color);\n\n            function transitionTo(state) {\n                let targetData;\n                if (state === \"logo\") {\n                    targetData = logoPoints;\n                } else if (state === \"shuffle1\") {\n                    targetData = shuffled1;\n                } else if (state === \"shuffle2\") {\n                    targetData = shuffled2;\n                } else {\n                    targetData = particles.map(() =&gt; ({\n                        x: Math.random() * width,\n                        y: Math.random() * height,\n                        color: \"white\"\n                    }));\n                }\n\n                circles.transition()\n                    .duration(2000)\n                    .ease(d3.easeCubicInOut)\n                    .attr(\"cx\", (d, i) =&gt; targetData[i].x)\n                    .attr(\"cy\", (d, i) =&gt; targetData[i].y)\n                    .attr(\"fill\", (d, i) =&gt; targetData[i].color);\n\n                currentState = (currentState + 1) % states.length;\n            }\n\n            function animateLoop() {\n                transitionTo(states[currentState]);\n                setTimeout(animateLoop, 3000);\n            }\n\n            animateLoop();\n        };\n    &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;);\n\n\n    \n\n\n    \n\n    \n\n);"
  },
  {
    "objectID": "software/diffustats.html",
    "href": "software/diffustats.html",
    "title": "diffuStats: compute diffusion scores over networks",
    "section": "",
    "text": "The general purpose diffuStats R package offers a collection of seven network propagation scores and five graph kernels. Those find application in ubiquitous computational biology applications, being one representative example the propagation of genetic information (e.g. disease-associated genes) in a gene-gene or a protein-protein interaction network. A distinctive feature of diffuStats is the implementation of statistically normalised scores, which address the recurrent question of how would the propagation of a randomised input look. It offers parametric, exact z-scores as well as permutation-based empirical probabilities.\nThe diffuStats software was published in:\n\nPicart-Armada, S., Thompson, W. K., Buil, A., & Perera-Lluna, A. (2018). diffuStats: an R package to compute diffusion-based scores on biological networks. Bioinformatics, 34(3), 533-534.\n\nGeneral guidelines on how to choose the scores, along with mathematical properties of the normalised and unnormalised scores, were published in:\n\nPicart-Armada, S., Thompson, W. K., Buil, A., & Perera-Lluna, A. (2020). The effect of statistical normalisation on network propagation scores. Bioinformatics, btaa896.\n\nFrom versions 1.10.2/1.11.2 onwards, diffuStats provides functions to export the exact statistical moments (means and variances), see ?moments. Now the users can characterise the systematic biases in the diffusion scores in their domain of application.\n\n\n\ndiffuStats is part of Bioconductor, and can be installed using\n\nBiocManager::install(\"diffuStats\")\n\nFor the development version, you can also install the package through R CMD INSTALL or through devtools::install_github(\"b2slab/diffuStats\"), which points to its GitHub repository.",
    "crumbs": [
      "Software",
      "diffuStats"
    ]
  },
  {
    "objectID": "software/diffustats.html#introduction",
    "href": "software/diffustats.html#introduction",
    "title": "diffuStats: compute diffusion scores over networks",
    "section": "",
    "text": "The general purpose diffuStats R package offers a collection of seven network propagation scores and five graph kernels. Those find application in ubiquitous computational biology applications, being one representative example the propagation of genetic information (e.g. disease-associated genes) in a gene-gene or a protein-protein interaction network. A distinctive feature of diffuStats is the implementation of statistically normalised scores, which address the recurrent question of how would the propagation of a randomised input look. It offers parametric, exact z-scores as well as permutation-based empirical probabilities.\nThe diffuStats software was published in:\n\nPicart-Armada, S., Thompson, W. K., Buil, A., & Perera-Lluna, A. (2018). diffuStats: an R package to compute diffusion-based scores on biological networks. Bioinformatics, 34(3), 533-534.\n\nGeneral guidelines on how to choose the scores, along with mathematical properties of the normalised and unnormalised scores, were published in:\n\nPicart-Armada, S., Thompson, W. K., Buil, A., & Perera-Lluna, A. (2020). The effect of statistical normalisation on network propagation scores. Bioinformatics, btaa896.\n\nFrom versions 1.10.2/1.11.2 onwards, diffuStats provides functions to export the exact statistical moments (means and variances), see ?moments. Now the users can characterise the systematic biases in the diffusion scores in their domain of application.",
    "crumbs": [
      "Software",
      "diffuStats"
    ]
  },
  {
    "objectID": "software/diffustats.html#installation",
    "href": "software/diffustats.html#installation",
    "title": "diffuStats: compute diffusion scores over networks",
    "section": "",
    "text": "diffuStats is part of Bioconductor, and can be installed using\n\nBiocManager::install(\"diffuStats\")\n\nFor the development version, you can also install the package through R CMD INSTALL or through devtools::install_github(\"b2slab/diffuStats\"), which points to its GitHub repository.",
    "crumbs": [
      "Software",
      "diffuStats"
    ]
  },
  {
    "objectID": "software/diffustats.html#news",
    "href": "software/diffustats.html#news",
    "title": "diffuStats: compute diffusion scores over networks",
    "section": "News",
    "text": "News\nFile NEWS.md keeps track of the additions and bug fixes of each package version.",
    "crumbs": [
      "Software",
      "diffuStats"
    ]
  },
  {
    "objectID": "software/intcorr.html",
    "href": "software/intcorr.html",
    "title": "Computational Methods for Correcting the Drift in LC/MS Metabolomic Data in R: intCor Package",
    "section": "",
    "text": "Liquid Chromatography coupled to Mass Spectrometry (LC/MS) has become widely used in metabolomics. Several artifacts have been identified during the acquisition step in large LC/MS metabolomics experiments, including ion suppression, carryover, or changes in sensitivity and intensity. The drift effects of peak intensity are among the most frequent issues and may constitute the main source of variance in the data, leading to misleading statistical results. This document introduces the intCor package, which applies a methodology based on a common variance analysis prior to data normalization to address drift effects. This approach was tested and compared with four other methods using the Dunn and Silhouette indices of Quality Control classes, demonstrating superior performance.\nKeywords: Metabolomics, Drift Correction, LC/MS.",
    "crumbs": [
      "Software",
      "Intensity Drift Correction in LC/MS"
    ]
  },
  {
    "objectID": "software/intcorr.html#importing-data",
    "href": "software/intcorr.html#importing-data",
    "title": "Computational Methods for Correcting the Drift in LC/MS Metabolomic Data in R: intCor Package",
    "section": "Importing Data",
    "text": "Importing Data\nThe importData() function is used to read the samples or data sets that will be analyzed. It supports three input formats:\n\nA set of external files (e.g., CDF or mzXML)\nA matrix format\nAn xcmsSet object\n\n\nUsing an External Data Matrix\nA data table and a class vector can be used for importing the data. The data matrix should have samples as columns and variables (time or masses) as rows. The class vector should contain class names, with its components corresponding to the order of the matrix columns.\n\n# Load example data\nlibrary(intCor)\ndata(intCorData)\n\n# Import data matrix\nintCor_table &lt;- importData(data = dataMatrix, classes = classes)\n\n\n\nUsing an xcmsSet Object\nThe importData() function also supports an xcmsSet object from the XCMS package. If class information is not provided, it will be retrieved from the xcmsSet object.\n\n# Load xcmsSet data\nlibrary(xcms)\ndata(intCorXCMS)\nnormInt_xcms &lt;- importData(data = xcg)\n\n\n\nUsing Sample Files\nIf CDF or mzXML files are provided, intCor performs drift correction directly on the chromatograms. The following example demonstrates how to import data using CDF files and a metadata CSV file.\n\n# Importing CDF files\ntab &lt;- read.csv(\"sampTable.csv\")\nnormInt &lt;- importData(dataDir = \"data\", fileType = \"cdf\", tabName = \"sampTable.csv\")",
    "crumbs": [
      "Software",
      "Intensity Drift Correction in LC/MS"
    ]
  },
  {
    "objectID": "software/intcorr.html#download",
    "href": "software/intcorr.html#download",
    "title": "Computational Methods for Correcting the Drift in LC/MS Metabolomic Data in R: intCor Package",
    "section": "Download",
    "text": "Download\n\nR package:intCor_1.03.tar.gz\nnetCDF files for the vignette: intCorData\nVignette: intCor_vignette",
    "crumbs": [
      "Software",
      "Intensity Drift Correction in LC/MS"
    ]
  },
  {
    "objectID": "software/miss.html",
    "href": "software/miss.html",
    "title": "MISS: Nonlinear Genetic Association.",
    "section": "",
    "text": "MISS is a a nonlinear methodology based on mutual information for genetic association.\n\n\n\nThe an information theoretic approach to genetic association, which has been integrated jointly with a feature selection algorithm. The algorithm was been tested on a synthetic data with a controlled phenotype and in the particular case of the F7 gene. This algorithm proposes a multi-target approach and unveils combinations of SNPs that explain more significant information of the phenotype than their individual polymorphisms.\n\n\n\nThe software package with documentation can be found here.\nThe paper describing MISS can be found here\n\n\n\n\n\nBrunel, H.; Gallardo, J.; Buil, A.; Vallverdu, M.; Soria, J.; Caminal, P.; Perera, A. (2010). MISS: a non-linear methodology based on mutual information for genetic association studies in both population and sib-pairs analysis. Bioinformatics, 26, 1811-1818.",
    "crumbs": [
      "Software",
      "MISS"
    ]
  },
  {
    "objectID": "software/miss.html#download",
    "href": "software/miss.html#download",
    "title": "MISS: Nonlinear Genetic Association.",
    "section": "",
    "text": "The software package with documentation can be found here.\nThe paper describing MISS can be found here",
    "crumbs": [
      "Software",
      "MISS"
    ]
  },
  {
    "objectID": "software/miss.html#citation",
    "href": "software/miss.html#citation",
    "title": "MISS: Nonlinear Genetic Association.",
    "section": "",
    "text": "Brunel, H.; Gallardo, J.; Buil, A.; Vallverdu, M.; Soria, J.; Caminal, P.; Perera, A. (2010). MISS: a non-linear methodology based on mutual information for genetic association studies in both population and sib-pairs analysis. Bioinformatics, 26, 1811-1818.",
    "crumbs": [
      "Software",
      "MISS"
    ]
  },
  {
    "objectID": "software/fella.html",
    "href": "software/fella.html",
    "title": "FELLA: Interpretation and Enrichment for Metabolomics Data",
    "section": "",
    "text": "Overview\nFELLA is an R package designed for the enrichment of metabolomics data using KEGG entries. Given a set of affected compounds, FELLA suggests related reactions, enzymes, modules, and pathways through label propagation in a knowledge model network. The resulting subnetwork can be visualized and exported.\n\nThis package is maintained by Sergio Picart-Armada &lt;sergi.picart at upc.edu&gt;\n\n\n\nInstallation\nTo install FELLA, start R (version 4.4 or later) and enter:\n\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"FELLA\")\n\nFor older versions of R, please refer to the appropriate Bioconductor release.\n\n\nDocumentation\nTo view documentation for the version of this package installed in your system, start R and enter:\n\nbrowseVignettes(\"FELLA\")\n\nAvailable vignettes include:\n\nExample: a fatty liver study on Mus musculus\nExample: oxybenzone exposition in gilt-head bream\nFELLA\nQuick start\n\nThe reference manual and news updates are also available.\n\n\nCitation:\n\nFrom within R, enter citation(“FELLA”):\nPicart-Armada S, Fernandez-Albert F, Vinaixa M, Yanes O, Perera-Lluna A (2018). “FELLA: an R package to enrich metabolomics data.”  BMC Bioinformatics, 19(1), 538. doi:10.1186/s12859-018-2487-5.\nPicart-Armada S, Fernandez-Albert F, Vinaixa M, Rodriguez MA, Aivio S, Stracker TH, Yanes O, Perera-Lluna A (2017). “Null diffusion-based enrichment for metabolomics data.” PLOS ONE, 12(12), e0189012. doi:10.1371/journal.pone.0189012.\n\nFor more information, visit the Bioconductor page for FELLA.",
    "crumbs": [
      "Software",
      "FELLA"
    ]
  },
  {
    "objectID": "software/chemosensors.html",
    "href": "software/chemosensors.html",
    "title": "chemosensors",
    "section": "",
    "text": "Chemosensors is an R Software tool that allows for the design of synthetic experiments with so-called virtual gas sensor arrays. The package was developed by Andrey Ziyatdinov and Alexandre Perera. This R package was a product of the Neurochem project, an 7FP Bio-ICT project focused on Bioengineering and bioinspired computing.\nThe R package and tutorial can be found here.\n\n\nThe command in R to install the package:\n\ninstall.packages(\"chemosensors\")\n\nThe stable version of chemosensors package from the CRAN repository will be installed\n\n\n\nChemosensors package can be installed as a regular R package from the R-Forge repository. The command to type in R:\n\ninstall.packages(\"chemosensors\", dep=TRUE, repos=\"http://r-forge.r-project.org\")\n\nThat will install the latest development version with all dependencies. Please let us know if you have any problems related to installation or running the software.\n\n\n\nHelp pages in html format are available on http://chemosensors.r-forge.r-project.org/html. Thanks to devtools and staticdocs.\n\n\n\nYou might prefer to start with demos of the package. To see the list of available demos type in R:\n\ndemo(package=\"chemosensors\")\nBasic commands to generate synthetic data from a virtual sensor array could be:\n# concentration matrix of 3 gas classes: A, C and AC\nconc &lt;- matrix(0, 300, 3)\nconc[1:100, 1] &lt;- 0.05 # A\nconc[101:200, 3] &lt;- 1 # C\nconc[201:300, 1] &lt;- 0.05 # AC\nconc[201:300, 3] &lt;- 1 # AC\n\nconc &lt;- conc[sample(1:nrow(conc)  ), ]\n\n# sensor array of 5 sensors with parametrized noise levels\nsa &lt;- SensorArray(num=1:5, csd=0.1, ssd=0.1, dsd=0.1)\n\n# get information about the array\nprint(sa)\nplot(sa)\n\n# generate the data\nsdata &lt;- predict(sa, conc)\n\n# plot the data\nplot(sa, \"prediction\", conc=conc)\n\n\n\n\n\nAndrey Ziyatdinov, Alexandre Perera, Synthetic benchmarks for machine olfaction: Classification, segmentation and sensor damage Data in Brief,Volume 3, 2015, Pages 126-130, ISSN 2352-3409, https://doi.org/10.1016/j.dib.2015.02.011.\nhttp://www.sciencedirect.com/science/article/pii/S2352340915000220\n\nThe three synthetic datasets mentioned in the paper can be downloaded (1Gb approx) following this link.\n\n\n\n\nAlexandre Perera Email: alexandre.perera [at] upc.edu\nAndrey Ziyatdinov Email: andrey.ziyatdinov [at] upc.edu\n\n\n\n\nThis work was funded from the European Community’s Seventh Framework Programme (FP7/2007-2013) under grant agreement no. 216916: Biologically inspired computation for chemical sensing (NEUROChem), the Ramon y Cajal program from the Spanish Ministerio de Educacion y Ciencia and TEC2010-20886-C02-02. CIBER-BBN is an initiative of the Spanish ISCIII.",
    "crumbs": [
      "Software",
      "Chemosensors"
    ]
  },
  {
    "objectID": "software/chemosensors.html#installation-from-cran-recommended",
    "href": "software/chemosensors.html#installation-from-cran-recommended",
    "title": "chemosensors",
    "section": "",
    "text": "The command in R to install the package:\n\ninstall.packages(\"chemosensors\")\n\nThe stable version of chemosensors package from the CRAN repository will be installed",
    "crumbs": [
      "Software",
      "Chemosensors"
    ]
  },
  {
    "objectID": "software/chemosensors.html#installation-from-r-forge",
    "href": "software/chemosensors.html#installation-from-r-forge",
    "title": "chemosensors",
    "section": "",
    "text": "Chemosensors package can be installed as a regular R package from the R-Forge repository. The command to type in R:\n\ninstall.packages(\"chemosensors\", dep=TRUE, repos=\"http://r-forge.r-project.org\")\n\nThat will install the latest development version with all dependencies. Please let us know if you have any problems related to installation or running the software.",
    "crumbs": [
      "Software",
      "Chemosensors"
    ]
  },
  {
    "objectID": "software/chemosensors.html#documentation",
    "href": "software/chemosensors.html#documentation",
    "title": "chemosensors",
    "section": "",
    "text": "Help pages in html format are available on http://chemosensors.r-forge.r-project.org/html. Thanks to devtools and staticdocs.",
    "crumbs": [
      "Software",
      "Chemosensors"
    ]
  },
  {
    "objectID": "software/chemosensors.html#examples",
    "href": "software/chemosensors.html#examples",
    "title": "chemosensors",
    "section": "",
    "text": "You might prefer to start with demos of the package. To see the list of available demos type in R:\n\ndemo(package=\"chemosensors\")\nBasic commands to generate synthetic data from a virtual sensor array could be:\n# concentration matrix of 3 gas classes: A, C and AC\nconc &lt;- matrix(0, 300, 3)\nconc[1:100, 1] &lt;- 0.05 # A\nconc[101:200, 3] &lt;- 1 # C\nconc[201:300, 1] &lt;- 0.05 # AC\nconc[201:300, 3] &lt;- 1 # AC\n\nconc &lt;- conc[sample(1:nrow(conc)  ), ]\n\n# sensor array of 5 sensors with parametrized noise levels\nsa &lt;- SensorArray(num=1:5, csd=0.1, ssd=0.1, dsd=0.1)\n\n# get information about the array\nprint(sa)\nplot(sa)\n\n# generate the data\nsdata &lt;- predict(sa, conc)\n\n# plot the data\nplot(sa, \"prediction\", conc=conc)",
    "crumbs": [
      "Software",
      "Chemosensors"
    ]
  },
  {
    "objectID": "software/chemosensors.html#further-information-at",
    "href": "software/chemosensors.html#further-information-at",
    "title": "chemosensors",
    "section": "",
    "text": "Andrey Ziyatdinov, Alexandre Perera, Synthetic benchmarks for machine olfaction: Classification, segmentation and sensor damage Data in Brief,Volume 3, 2015, Pages 126-130, ISSN 2352-3409, https://doi.org/10.1016/j.dib.2015.02.011.\nhttp://www.sciencedirect.com/science/article/pii/S2352340915000220\n\nThe three synthetic datasets mentioned in the paper can be downloaded (1Gb approx) following this link.",
    "crumbs": [
      "Software",
      "Chemosensors"
    ]
  },
  {
    "objectID": "software/chemosensors.html#contacts",
    "href": "software/chemosensors.html#contacts",
    "title": "chemosensors",
    "section": "",
    "text": "Alexandre Perera Email: alexandre.perera [at] upc.edu\nAndrey Ziyatdinov Email: andrey.ziyatdinov [at] upc.edu",
    "crumbs": [
      "Software",
      "Chemosensors"
    ]
  },
  {
    "objectID": "software/chemosensors.html#acknowledgment",
    "href": "software/chemosensors.html#acknowledgment",
    "title": "chemosensors",
    "section": "",
    "text": "This work was funded from the European Community’s Seventh Framework Programme (FP7/2007-2013) under grant agreement no. 216916: Biologically inspired computation for chemical sensing (NEUROChem), the Ramon y Cajal program from the Spanish Ministerio de Educacion y Ciencia and TEC2010-20886-C02-02. CIBER-BBN is an initiative of the Spanish ISCIII.",
    "crumbs": [
      "Software",
      "Chemosensors"
    ]
  },
  {
    "objectID": "blog/posts/20180207_sr4/index.html",
    "href": "blog/posts/20180207_sr4/index.html",
    "title": "B2SLab Takes Part In Share4Rare, A European Project Focused On Rare Pediatric Diseases",
    "section": "",
    "text": "MAIT\n\n\n\nShare4Rare (S4R) is a project funded by the European Commission that aims for a collective awareness platform of patients, caregivers, researchers and other stakeholders involved in Rare Diseases towards improving quality of life, disease management and collection of scientific knowledge and data on Rare Diseases.\nThe platform will be built around three important pillars: Education, Sharing and Research. It is based on the expertise of the coordinator managing a previous project: Rare Commons (RC). This is a platform that currently includes 9 different diseases. RC has demonstrated that the collective intelligence coming from parents of children with rare diseases is needed to increase the current knowledge available. A broad sample from the patient community has been identified, in several cases with a higher number of patients compared with previous initiatives.\nS4R is proposing dealing with two important challenges that will improve the previous experience with the RC project: to increase the power of the users of the platform, developing a platform based on a bottom-up model with a patient-centered design, and to promote synergy by grouping diseases that share common features, instead of individual diseases.\nSeven European institutions or associations participate in this project under the coordination of Sant Joan de Déu Foundation. The Universitat Politècnica de Catalunya is one of these partners through B2SLab’s participation.\nThe voice of the patients is at the heart of the project. Two relevant patient organizations are part of the consortium: The World Duchenne Organization (UPPMD) and the Melanoma Patient Network Europe (MPNE). Other members of the consortium are focused on other important areas of expertise: technology developers (Omada Interactiva), biostatistics (Universitat Politècnica de Catalunya), social innovation (The Synergist), clinical background in neuromuscular disorders (Newcastle University) and socioeconomic impact (Asserta).\nThe launch meeting of the project was held in Barcelona on the 11th and 12th of January. During the next year, centered on the development of the platform, several activities are scheduled to ensure that the voice of the patient is included from the outset. The platform will be accessible for the users at the beginning of 2019 and is going to be piloted with two specific groups of diseases: neuromuscular disorders and paediatric rare tumors."
  },
  {
    "objectID": "blog/posts/20250204_NewWeb/index.html",
    "href": "blog/posts/20250204_NewWeb/index.html",
    "title": "We have a new website!",
    "section": "",
    "text": "After a long time without updating (although busy doing stuff) we have updated our site. The approach of the update of course is try to reduce the maintenance time and add interoperativity with the University bibliographic system at futur so that our publication list is always updated (or more often updated).\nSo now the website pulls the team info from the linked google spreadsheet and it also pulls the publications list from futur.upc.edu at build.\nThe website is coded with quarto. This means that it is essentially build with Markdown. We thank the team of posit.co and quarto for building this nice tools.\nThis is kind of following the philosophy of org-mode which Àlex has been using for building slides and teaching material during the last years. This allows us to mix python/R and other code for building reports, papers and slides in a reproducible approach and open science.\nThanks for reading!"
  },
  {
    "objectID": "blog/posts/20250204_NewWeb/index.html#welcome-to-our-new-website",
    "href": "blog/posts/20250204_NewWeb/index.html#welcome-to-our-new-website",
    "title": "We have a new website!",
    "section": "",
    "text": "After a long time without updating (although busy doing stuff) we have updated our site. The approach of the update of course is try to reduce the maintenance time and add interoperativity with the University bibliographic system at futur so that our publication list is always updated (or more often updated).\nSo now the website pulls the team info from the linked google spreadsheet and it also pulls the publications list from futur.upc.edu at build.\nThe website is coded with quarto. This means that it is essentially build with Markdown. We thank the team of posit.co and quarto for building this nice tools.\nThis is kind of following the philosophy of org-mode which Àlex has been using for building slides and teaching material during the last years. This allows us to mix python/R and other code for building reports, papers and slides in a reproducible approach and open science.\nThanks for reading!"
  },
  {
    "objectID": "blog/posts/20141009_mait/index.html",
    "href": "blog/posts/20141009_mait/index.html",
    "title": "MAIT Package Now Available In Bioconductor!",
    "section": "",
    "text": "MAIT\n\n\n\nThe MAIT package for analysing LC/MS Metabolomic data, as discussed in a previous post, was published in a collaboration between the B2SLab and the Nutrimetabolomics lab in the Oxford Bioinformatics journal:\n\nFernández-Albert F, Llorach R, Andrés-Lacueva C, Perera-Lluna A. An R package to analyse LC/MS metabolomic data: MAIT (Metabolite Automatic Identification Toolkit). Bioinformatics (2014). doi: 10.1093/bioinformatics/btu136.\n\nMAIT package is now available through the Bioconductor repository. All the upcoming new versions of the MAIT packages will be published in Bioconductor as well."
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "b2slab website",
    "section": "",
    "text": "b2slab website\nThis is the b2slab website.\n\n\nContributing\nGuys and girls, an important note: - Please I need each one of you to (staff/phd/visitors and all) fill out this form. You will need a picture of yourself, square format, of around 640x640px approx tp fill the form. - This is required as the new website will pull everyone of us from the linked google spreadsheet. You can see the tests if this on the deployed new site at http://b2slab.upc.edu. Some random notes about the website: - Now the website pulls the team info from the linked google spreadsheet - It also pulls the publications list from futur.upc.edu. Remember you need to add all your production to drac so it is uploaded there. - We will all need to create personal websites. - The website is coded with quarto. This means that is essentially build with markdown. You can create a quarto document within Rstudio with your personal website and add it to the ~web-and-comms channel. Please join all that channel as we will coordinate the content on there and release this one. I will upload at some point a nice template for a personal site.\nPlease find at teams/alexandre-perera-lluna folder a template for personal website, if you keep the r cells you will get your production automcatically placed form futur. To get the link in futur you need to:\n\nsearch for your profile at https://futur.upc.edu\nFilter for Article en revista indexada\nClick “Exportar”\nClick Gestior de referencies\nClick OK\nA file will download, discard the downloaded file, got to downloads in your browser and copy the address of the file, something like “https://futur.upc.edu/RIS/AlexandrePereraLluna/as/YXV0b3JpYUFydGljbGVSZXZpc3RhSW5kZXhhZGE=/?locale=en”, add this file in the R section on the qmd of the template.\nCreate your personal page and add a forder with your name. Create a commit to the github in theteam/folder, or send the zip to @alex\n\n\n\nDeployment\ncall:\nbash deploy.sh\nYou will need credentials to the b2sserver."
  },
  {
    "objectID": "team/enrico-manzini/index.html",
    "href": "team/enrico-manzini/index.html",
    "title": "Enrico Manzini",
    "section": "",
    "text": "Welcome to my page! My name is Enrico Manzini. I earned my Bachelor’s degree in Information Engineering from the University of Padua (UNIPD). I then participated in the T.I.M.E. Double Degree program, through which I obtained a Master’s degree in Biomedical Engineering (UNIPD, Padova, Italy) and a Master’s degree in Automatic Control & Robotics (UPC, Barcelona, Spain).\nCurrently, I’m in the final stages of my PhD at B2SLab (legends say it actually does end someday!) under the supervision of Alex Perera. My research focuses on deep learning (DL) for Electronic Health Records (EHRs), modeling chronic diseases like Type 2 Diabetes and COPD, and predicting clinically relevant outcomes using various DL architectures (e.g., transformers, RNNs, …)."
  },
  {
    "objectID": "team/enrico-manzini/index.html#bio",
    "href": "team/enrico-manzini/index.html#bio",
    "title": "Enrico Manzini",
    "section": "",
    "text": "Welcome to my page! My name is Enrico Manzini. I earned my Bachelor’s degree in Information Engineering from the University of Padua (UNIPD). I then participated in the T.I.M.E. Double Degree program, through which I obtained a Master’s degree in Biomedical Engineering (UNIPD, Padova, Italy) and a Master’s degree in Automatic Control & Robotics (UPC, Barcelona, Spain).\nCurrently, I’m in the final stages of my PhD at B2SLab (legends say it actually does end someday!) under the supervision of Alex Perera. My research focuses on deep learning (DL) for Electronic Health Records (EHRs), modeling chronic diseases like Type 2 Diabetes and COPD, and predicting clinically relevant outcomes using various DL architectures (e.g., transformers, RNNs, …)."
  },
  {
    "objectID": "team/enrico-manzini/index.html#teaching",
    "href": "team/enrico-manzini/index.html#teaching",
    "title": "Enrico Manzini",
    "section": "Teaching",
    "text": "Teaching\nMeanwhile, I contribute to teaching in the following courses:\n\nDeep Learning Methods for Biomedicine, a deep learning course at the Master’s degree in Biomedical Engineering at Universitat de Barcelona (UB).\nScientific Python for Data Analysis, Python course for Data Analysis for the Aurora consortium of research intensive universities."
  },
  {
    "objectID": "team/enrico-manzini/index.html#publications",
    "href": "team/enrico-manzini/index.html#publications",
    "title": "Enrico Manzini",
    "section": "Publications",
    "text": "Publications\nA possibly incomplete and malformed list of publications is included below:\n\n2022\n\n\n1. Mapping layperson medical terminology into the Human Phenotype Ontology using neural machine translation modelsManzini, E. and Garrido, J. and Fonollosa, J. and Perera, A.Expert systems with applications, Vol. 204, Issue C (2022)[DOI]\n\n\n2. Longitudinal deep learning clustering of Type 2 Diabetes Mellitus trajectories using routinely collected health recordsManzini, E. and Vlacho, B. and Franch, J. and Escudero, J. and G’enova, A. and Reixach-Espaulella, E. and Andr’es, E. and Pizarro, I. and Portero, J. and Mauricio Puente, D’idac and Perera, A.Journal of biomedical informatics, Vol. 135, Issue Article 104218 (2022)[DOI]"
  },
  {
    "objectID": "team/joana-gelabert-xirinachs/index.html",
    "href": "team/joana-gelabert-xirinachs/index.html",
    "title": "Joana Gelabert Xirinachs",
    "section": "",
    "text": "Welcome to my site! My name is Joana Gelabert Xirinachs. I hold a degree in Biomedical Engineering (Universitat Pompeu Fabra) and another in Philosophy (Universitat de Barcelona). I’m currently starting my PhD in Bioinformatics at the B2SLab—hopefully, I’ll remember to update this site so I’m not forever stuck at the “just starting” phase!\nMy PhD is supervised by Alex Perera and Jordi Fonollosa, and my research focuses on analyzing and predicting the progression of type 2 diabetes. I work with large Electronic Health Record (EHR) datasets, combining linear models and deep learning algorithms to make sense of complex data. My thesis builds on research developed at the lab, including the work of Enrico Manzini."
  },
  {
    "objectID": "team/joana-gelabert-xirinachs/index.html#bio",
    "href": "team/joana-gelabert-xirinachs/index.html#bio",
    "title": "Joana Gelabert Xirinachs",
    "section": "",
    "text": "Welcome to my site! My name is Joana Gelabert Xirinachs. I hold a degree in Biomedical Engineering (Universitat Pompeu Fabra) and another in Philosophy (Universitat de Barcelona). I’m currently starting my PhD in Bioinformatics at the B2SLab—hopefully, I’ll remember to update this site so I’m not forever stuck at the “just starting” phase!\nMy PhD is supervised by Alex Perera and Jordi Fonollosa, and my research focuses on analyzing and predicting the progression of type 2 diabetes. I work with large Electronic Health Record (EHR) datasets, combining linear models and deep learning algorithms to make sense of complex data. My thesis builds on research developed at the lab, including the work of Enrico Manzini."
  },
  {
    "objectID": "team/index.html",
    "href": "team/index.html",
    "title": "Current Team",
    "section": "",
    "text": "I hold a degree in Physics, a second degree in electrical engineering, and a PhD in physics by the University of Barcelona. I am currently leading the B2SLab. This lab belongs to the Institut de Recerca i Innovació en Salut (IRIS).\n\nhttp://b2slab.upc.edu/team/alexandre-perera-lluna/\n\n\n\n\n\n\n\n\n\nJordi Fonollosa (PhD in Electronic Engineering, 2009) is Associate Professor at the Department of Automatic Control (Universitat Politècnica de Catalunya), under the Serra-Hunter program. Currently, I am the UPC coordinator for the Inter-University Master’s Program in Biomedical Engineering (UB+UPC).\n\nhttp://b2slab.upc.edu/team/jordi-fonollosa/",
    "crumbs": [
      "Our Team",
      "Current Team"
    ]
  },
  {
    "objectID": "team/index.html#staff",
    "href": "team/index.html#staff",
    "title": "Current Team",
    "section": "",
    "text": "I hold a degree in Physics, a second degree in electrical engineering, and a PhD in physics by the University of Barcelona. I am currently leading the B2SLab. This lab belongs to the Institut de Recerca i Innovació en Salut (IRIS).\n\nhttp://b2slab.upc.edu/team/alexandre-perera-lluna/\n\n\n\n\n\n\n\n\n\nJordi Fonollosa (PhD in Electronic Engineering, 2009) is Associate Professor at the Department of Automatic Control (Universitat Politècnica de Catalunya), under the Serra-Hunter program. Currently, I am the UPC coordinator for the Inter-University Master’s Program in Biomedical Engineering (UB+UPC).\n\nhttp://b2slab.upc.edu/team/jordi-fonollosa/",
    "crumbs": [
      "Our Team",
      "Current Team"
    ]
  },
  {
    "objectID": "team/index.html#phd-students",
    "href": "team/index.html#phd-students",
    "title": "Current Team",
    "section": "PhD Students",
    "text": "PhD Students\n\n\n\n\n\n\nAitor Moruno Cuenca\n\n\nI am an industrial PhD candidate in Bioinformatics and a Senior Data Scientist R&D at Almirall S.A. I started my career as a Biostatistician in clinical trials, and currently my research at B2SLab is focused on developing new computational methods to quantitatively assess preclinical disease models using omics data. I completed a BSc Statistics, BA Economics and MSc Biostatistics & Bioinformatics.\n\nhttp://b2slab.upc.edu/team/aitor-moruno-cuenca/\n\n\n\n\n\n\n\n\nBlanca Alaejos Pardo\n\n\nI I hold a bachelor’s and master’s degree in Biomedical Engineering and am currently a PhD student in Bioinformatics at the B2Slab, working in collaboration with Sant Joan de Déu Hospital.\n\nhttp://b2slab.upc.edu/team/blanca-alaejos-pardo/,\n\n\n\n\n\n\n\n\nEnrico Manzini\n\n\nHi! I’m Enrico, a PhD student at the B2SLab. I work with deep learning and Electronic Health Records (EHRs) to better understand and predict outcomes for chronic diseases like Type 2 Diabetes and COPD. I have a double master’s degree in Biomedical Engineering from UNIPD (Italy) and Automatic Control & Robotics from UPC (Spain).\n\nhttps://b2slab.upc.edu/team/enrico-manzini\n\n\n\n\n\n\n\n\nHelena Rodríguez González\n\n\nI hold a Bachelor’s degree in Biomedical Engineering and a Master’s in Neuroengineering and Rehabilitation. Currently, I am a PhD student in Biomedical Engineering, specializing in rare neurometabolic disorders through a collaborative research program between B2Slab and Sant Joan de Déu Hospital.\n\nhttps://b2slab.upc.edu/team/helena-rodriguez-gonzalez/\n\n\n\n\n\n\n\n\nJoana Gelabert Xirinachs\n\n\nI hold a bachelor’s and master’s degree in Biomedical Engineering, as well as a degree in Philosophy. I am currently a PhD student in the Bioinformatics program, working with Electronic Health Records of patients diagnosed with type 2 diabetes to analyze and predict the progression of this complex disease.\n\nhttps://b2slab.upc.edu/team/joana-gelabert-xirinachs/\n\n\n\n\n\n\n\n\nJoshua Llano\n\n\nHi! I’m Joshua, a PhD student working on epigenetics and machine learning to improve early classification of pediatric tumors. My research is part of a collaboration with Hospital Sant Joan de Déu in Barcelona for a project funded by La Marató de TV3. I have a Bachelor’s in Biomedical Engineering from UPC (2017) and a Master’s from UB-UPC (2018). Oh, and I also have two bikes!\n\nhttps://b2slab.upc.edu/team/joshua-llano\n\n\n\n\n\n\n\n\nMaria Barranco Altirriba\n\n\nI have a background in biomedical engineering, having completed both my bachelor’s and master’s degrees in the field. Currently, I’m working on my PhD, focused on metabolomics—both designing algorithms to enhance data analysis and interpretation, and analyzing metabolomics data to gain deeper insights into diabetes mellitus and its complications.\n\nhttp://b2slab.upc.edu/team/maria-barranco/",
    "crumbs": [
      "Our Team",
      "Current Team"
    ]
  },
  {
    "objectID": "team/index.html#technical-staff",
    "href": "team/index.html#technical-staff",
    "title": "Current Team",
    "section": "Technical Staff",
    "text": "Technical Staff\n\n\n\n\n\n\nRafael León Carrasco\n\n\nHello! My name is Rafael León Carrasco. I have a Bachelor’s in Chemical Engineering and a Master’s in Interdisciplinary & Innovative Engineering from the UPC. I am passionate about technology and data science, focusing on developing Machine Learning models for rare disease diagnosis and collaborating with hospitals for data analysis. I specialize in using graph models and neural networks for clinical data insights. I also have experience in programming and server management. With a strong engineering background, I enjoy facing complex challenges and quickly adapting to new technologies.\n\nhttp://b2slab.upc.edu/team/rafael-leon-carrasco/",
    "crumbs": [
      "Our Team",
      "Current Team"
    ]
  },
  {
    "objectID": "team/index.html#students-working-in-a-master-thesis-or-degree-thesis-at-b2slab",
    "href": "team/index.html#students-working-in-a-master-thesis-or-degree-thesis-at-b2slab",
    "title": "Current Team",
    "section": "Students working in a Master thesis or degree thesis at b2slab",
    "text": "Students working in a Master thesis or degree thesis at b2slab",
    "crumbs": [
      "Our Team",
      "Current Team"
    ]
  },
  {
    "objectID": "team/current.html",
    "href": "team/current.html",
    "title": "b2slab",
    "section": "",
    "text": "Who is who?.",
    "crumbs": [
      "Our Team",
      "Group Pictures!"
    ]
  },
  {
    "objectID": "team/current.html#group-pics",
    "href": "team/current.html#group-pics",
    "title": "b2slab",
    "section": "",
    "text": "Who is who?.",
    "crumbs": [
      "Our Team",
      "Group Pictures!"
    ]
  }
]